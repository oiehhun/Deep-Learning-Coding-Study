{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Module"
      ],
      "metadata": {
        "id": "ih0lhYogv72h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "cqjL-7_Gv23M"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset"
      ],
      "metadata": {
        "id": "A6NK2_HvwAfl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zesaRv5Sv-g-",
        "outputId": "c9b62cdf-8438-4299-f77a-5dc0b65ed083"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"x_train shape: {X_train.shape} - y_train shape: {y_train.shape}\")\n",
        "print(f\"x_test shape: {X_test.shape} - y_test shape: {y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AVBukXtjwGLi",
        "outputId": "7272fc8d-c2d6-43f0-f6f1-849d60da514c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (50000, 32, 32, 3) - y_train shape: (50000, 1)\n",
            "x_test shape: (10000, 32, 32, 3) - y_test shape: (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data augmentation"
      ],
      "metadata": {
        "id": "fcJ4XqDdweoz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = tf.keras.Sequential(\n",
        "    [\n",
        "        tf.keras.layers.Normalization(),\n",
        "        tf.keras.layers.Resizing(72,72),\n",
        "        tf.keras.layers.RandomFlip('horizontal'),\n",
        "        tf.keras.layers.RandomRotation(factor=0.02),\n",
        "        tf.keras.layers.RandomZoom(height_factor=0.2,width_factor=0.2)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "7SCh6s2awhNw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 정규화를 위해 사진의 평균과 분산 계산\n",
        "transform.layers[0].adapt(X_train)"
      ],
      "metadata": {
        "id": "G0xwiFuow2lS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ViT"
      ],
      "metadata": {
        "id": "3SbjvWaZwaE9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLP"
      ],
      "metadata": {
        "id": "1H8aLBiUwZ_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mlp(x, hidden_units, dropout_rate):\n",
        "  for units in hidden_units:\n",
        "    x = tf.keras.layers.Dense(units, activation=tf.nn.gelu)(x)\n",
        "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
        "  return x"
      ],
      "metadata": {
        "id": "E2QxJlk9wJSk"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Patch"
      ],
      "metadata": {
        "id": "mKJHVIw-xOl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Patches(tf.keras.layers.Layer):\n",
        "  def __init__(self, patch_size):\n",
        "    super().__init__()\n",
        "    self.patch_size = patch_size\n",
        "\n",
        "  def call(self, images):\n",
        "    batch_size = tf.shape(images)[0]\n",
        "    patches = tf.image.extract_patches(\n",
        "        images = images,\n",
        "        sizes = [1, self.patch_size, self.patch_size, 1],\n",
        "        strides = [1, self.patch_size, self.patch_size, 1],\n",
        "        rates = [1,1,1,1],\n",
        "        padding = 'VALID'\n",
        "    )\n",
        "    patch_dims = patches.shape[-1]\n",
        "    patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "    return patches"
      ],
      "metadata": {
        "id": "_MoZVFf0xN2w"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample = tf.image.resize(tf.convert_to_tensor([X_train[0]]), size=(72,72))\n",
        "sample.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YV97kTMDxotu",
        "outputId": "bbb8e985-624a-4e5d-d999-e4276b454819"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 72, 72, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = tf.shape(sample)\n",
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MqmPv5Yx6ng",
        "outputId": "8ecea325-0b16-4d26-b360-232b08aa4de4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([ 1, 72, 72,  3], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = a[0]\n",
        "batch_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZUarsJI5xtKP",
        "outputId": "0dceb43e-d47a-41df-9270-62f5a8952947"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=int32, numpy=1>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patches = tf.image.extract_patches(\n",
        "    images = sample,\n",
        "    sizes = [1,6,6,1],\n",
        "    strides = [1,6,6,1],\n",
        "    rates = [1,1,1,1],\n",
        "    padding = 'VALID'\n",
        ")"
      ],
      "metadata": {
        "id": "Fc6HqSbax4-2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patches.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xqqbYVi5yI_t",
        "outputId": "b397a2d9-de85-4946-8d51-50d35b3d5ebe"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 12, 12, 108])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "patch_dims = patches.shape[-1]"
      ],
      "metadata": {
        "id": "qtQ2eo60yJrC"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patches = tf.reshape(patches , [batch_size, -1, patch_dims])\n",
        "patches.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpuiCculyU4-",
        "outputId": "b3aa64ea-5681-4542-c131-7412e11c2115"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 144, 108])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "맨 마지막 차원의 108은 6 x 6 x 3 패치 이미지를 담고 있습니다.\n",
        "\n",
        "이와 같은 패치가 총 144개가 존재하므로 차원이 위와 같이 나옵니다(72/6 * 72/6)"
      ],
      "metadata": {
        "id": "hdNqr1sqzuAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nJB8ChmVyYuV"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Image size: 72 X 72\")\n",
        "print(f\"Patch size: 6 X 6\")\n",
        "print(f\"Patches per image: {patches.shape[1]}\")\n",
        "print(f\"Elements per patch: {patches.shape[-1]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIeNTEYkynst",
        "outputId": "bffaf1d2-e479-4049-dbd5-f2df2b982486"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Image size: 72 X 72\n",
            "Patch size: 6 X 6\n",
            "Patches per image: 144\n",
            "Elements per patch: 108\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n = int(np.sqrt(patches.shape[1]))\n",
        "plt.figure(figsize=(4, 4))\n",
        "for i, patch in enumerate(patches[0]):\n",
        "    ax = plt.subplot(n, n, i + 1)\n",
        "    patch_img = tf.reshape(patch, (6, 6, 3))\n",
        "    plt.imshow(patch_img.numpy().astype(\"uint8\"))\n",
        "    plt.axis(\"off\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "xDmDWBDryqe8",
        "outputId": "9e1ac7e3-00d2-474d-a2c6-8c5c61697af9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 144 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUkAAAFICAYAAADd1gwNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABLj0lEQVR4nO29edhuWVneufb4jt9wpqoCCqSEdmw1lkRRtNHWtK2C0YiIRpLCJBaiTCIyFMhQxSAkDLGqhDQpbA1KLAhpWhJymSiJmAgBHKgQOpIoVBUUVXWmb3iHPfYfpWc9972/b633AH11rnD//nqfs993r73X3nud/dzfMyR93/dOCCHEkaT/fx+AEEL894wWSSGECKBFUgghAmiRFEKIAFokhRAigBZJIYQIoEVSCCECaJEUQogAWiSFECJAvukXv/Wx3w5227aXPq/XK9hWVWhnifnsMMHnI390B9jf8g1fDfY4859nJa7pW+MC7PnEn86Etr3x9t8H+wU//u1gT8alH3OEv81THDdL/EGlaQbbnv6Gdzrm5p/7EbDhNwnuu08SsFertfmM83rDm94N9st+8vFgd5055hwv9XhUgl2Y7UnfwrZnve7tYL/hWU8E294L9rNzzjVNc+x3EzrXF73lX4D9qqfi+aSZn6ue7qOu78BumvrS57qpYNuNt/0u2C9/6v8G9sjMTZbyewSO03f+OPjcn3/zex3zyqfhWIl5T0nonSWle8POV07X89lveBfYtzwXr1FRFEd+PspO09x8xvv7Sc+/Gey3vfJpYDetn59ukMyXkGlsOtenvOgWsG+76WfA7sw4PO8dDYtXDI/hp298k4uhN0khhAigRVIIIQJokRRCiAAba5Ir0h07q0muWJNcg50nXiTI03DRobpC/chKLy3pI12D++qt3ZL+wZDu1rf1cZtc19H/JYn/QkfHdBRtjefUgs6Fx9mRXZu5rGk/TFPjvBvZxvUdaoMVa2utP4+E9D2mJs05pEm2Le7L3jdJGr5GLWmJvbkOrEEONElzPVujTx45Ds1rZ0X0wTHS/Wt0t47O/Sg6OhbUHen+pnvBSngt36QEXyPXtUd/dsN7I6RJDsahdaExQvhQksTz6c359axXEtV6CXZIk+z70DiXj94khRAigBZJIYQIsLG7ffbsWbCta7Fa4atwvUa3z0bulFn4hffwwjmwk5H/cVnj4dYdhi40buSPLxu5IA0ec2v+v6h7dDEadnvs5yT+/8xi/zzYNsyno3iFluyq8u5ZVaNbxBxexLmzu+JwmzzHc8yNW5km4Wu0d/6zOI5xsbqWJBDyuazFIS7M6uAi2PYcWnIRW3Ih7Xb+LrM+pHFaf+9kGc5Tkhx/fpu42/VyH+zMuLM2tIz37RyGG8U4vHAf2NZtLgp8jvIcn6PEHEcScbcvnsN7AQ454F4/YHvasMLjLt7P95yRvOjH/SB06vN7F9SbpBBCBNAiKYQQAbRICiFEgI01yQsXLoDdmnSzNWuSK9QkTbagG0dGXJIOVbb+B3WP2kmbYmpdlxvtqY7oNw2GLtiwgaajcIRB1If5hz4SauScW5LmZaWlpuHQFU7r83bdhDUvnjvQOwMZYc45l9mUt5huvEf6tBmHdTROtbP6UDpI+UOqBep39hw43dGG/DjnXGdCZDg8aDjOHthpN7n0mbXbobx1eZpksz7Ef0it/ocPB2ttNtTF6sBHsdhDfdpe8II0SE5ZRQ0vfI0OLuC9kATC2/ims7dn7N7eO48aqz3/nudioEmaOeYbfwP0JimEEAG0SAohRAAtkkIIEWBjTTKn5TQ1cXU9bctor1MTKDkvw5rA9gT1ku2pt7cmqEHOphgLORl7u6RSYEw+KA/lj4tlC45Pg7jADWLX6oZT6I7el3Nc1sk5ZzSeLA/PXUrakt0ZlxZLuICUuYZ5EY6NG41JCzYnxPIQx0LaeL1Y/FpR4vW158Dxe2mLtk3b67qw3pWkeC9YfZpT3AblzFK7LZ6imhd4TrmJw8xJk2xJp+sTr8MOdDgiJd0R9kNa8DAlMDny41FwaqnVN/nJ4GcFYh0HOYz8WzrfwPf5evfGVlqiEEJ8gdEiKYQQATZ3t+m1GwrjZPSnffI6ZsbF3orEAA3cbeNib03HuN8JudsTv70sI+72IBULLNjGr+/2zZ8rkBzF0N02ITP8Zfb1bbpgpGpOlpGLldrQHHZXaFhwt8PXqCR3uw+623gzZKDFxNzt4936NMWBUtJ40s5WJgqnJabk5vbmuDpyt7NAylu6wdMUdrcpLTHB407MfZlGJAR2t1lssQyqDR37zSEJV+237nbP7jWeD6R0RsK0eHvouDh0yobRxUKnjkJvkkIIEUCLpBBCBNAiKYQQAZKehQMhhBCX0JukEEIE0CIphBABtEgKIUSAjeMkH/qg02DbVJ+OOrMlLXafOznz8W4n5hi/9e/+FMtUfd/XnAJ7a+y/Px3hbyeUejg224sST+3V//wOsF/8w1/nkOM7qrVczqw2MXgUv/W69/xnxzzre7/iuKFcSu0B0ixQep5i0l77jj8E+2d/EM/Jxmf2g7g6PO7CBMLOpzivN/7GH4P9qqc8Cmw7Pw3FqCWDUnL+HDjl76Vv/xDYL37iN+ARB0qyDdtEHF8m7tXvxPN5wQ/RvWBaNGR0PQoqnZblx5fhuuFXPuCYV/7EN4Nty8Wl9HuOwW1q25IC5/mlb/sw2C/50a8H284HjzMsZ2c/43df/E/wGr3qbz8a7FBaYkNplvZe4W030r3wgideizsL/CVlXWE85nptOmdSe5E3/fbHj9/RX6A3SSGECKBFUgghAmiRFEKIABtrkhmX1jK6TUJ7YR1ny/RvODHD/Gtmh8qhTQq/rxElkOcJ5WF2tfkYzm2tVtS+wWqSpHe0Df6DbbkQK/HknHNNja0FrO6YU957zhql0axi7T15X63RfPqEs3fRzs04ZR4eZ0x6b+28BpSQRttyu89A+1mmrbENCGqS/G0u2WVatXLtPiKjnHh7jMmgRBfpd73NJ4+/c2SD9gHH66x8kqAVRop+9Vx0z+5rkH9+fGZ3Erm/e8rH7qwOzqfDZQVtLn6kjTHd2nD2wxxxPPfKauaNcreFEOILihZJIYQIsLG7XaYcNuBtLh9VUHms6cgPMx0fXzH5ge14SBNTEr2gd24uHQZmpPQSh8Sgu03uVzDcZJOsTv6OkSrI/WLXDyqmR0qlpVwQy1ZkHnSUY1/I7zvW9Y9DoqxLPejwx98NhAsxVYXutvXOueI5VzlPjFucxi5RsBsmbmM3F1zTDTrxsWRiS9gNpRu+v3NrBMfhZ9KOM/BsA+FTMTnJhiU5h5IAe9dNx/dNb7YFh3HLFYYVtmbnLQ20XOMxLVfebiISz1HoTVIIIQJokRRCiABaJIUQIsDGmuSYwm+s5sNhKwXJJWPTDmAUaQ0woi6GE9NpkTs2DjDjxpSHYbSGTUukE2CtKdlcs3HuCC0xoDNyGIkdmjXHAR2H25jUUdIZWT9rjFmtMWSJWSwoNKe1rRKOL53vnHO10bDqSAuCJYcAmc85targToPYYyMSasTiWfCaBsJyNggBSuhZsVPAem5K7zA2TKuPtb6gsKfOhGkNuxZyexGbzhqeu6o+vjUGa5A13Qs2NKeKiJLn9xa4L0hpxGOsAvYm3U0ZvUkKIUQALZJCCBFAi6QQQgS4DE2S0uWMQpRTXCTHVI4Lvz2W8lYWtC+TlpgNlnSOX/SfY8lH2UA/spokbePAMnt6G2Q5se4IcmAktA7SwvpI+1qO/WxtnCT9lo7JpghWdfigVmuMWbO6FWtYVYOaVW3sOhKPuW6O10YHujFdM4zHDI+zqlkLtJozD8P3gv9tLLXOuaFe1pixGyrxVaQUU2z0TNYrmSzB9F7QS3uOEaZWr9AyORInSTqj1ehZg1yTfrkyqcPrOvwgXTxcgl1V/vvrikqwdZSe29ln+/LRm6QQQgTQIimEEAE2drcnI3K3TdpTQeEkowxfnUcmLTHPI+lU5I0nxr1hF5lT0awfGwvNKch37wMhQFxsyPr1XF3nKAYVW6xJ/lxPrmFnUxgjzkJHFVl641b1gzRNPH87TtMfH9bhnHNVh26w3TUPU3MYiE0ni1wjDtcAi9zWYRiLrR4fHMZdPMTzTc0F51TYkqSI3D5BYSXJOefc2fPoNloXm91tzuCdlt6F5lA5puumYGf2mUxIxshQPukqU8m7w20MZ5baELCKKnGxW2wriK8iVbuWSzzmQ2MfLnBbS2nFXSi8bwP0JimEEAG0SAohRAAtkkIIESDpB+WQhRBC/CV6kxRCiABaJIUQIoAWSSGECLBxnOT3XPswsG0KVplisFSZocw5H/v4rtkE47v+4b/8U7B//vFfBrbt5sCxjTmVg7Llv7j81Q2/eQfYNz7hq8DGOEmE2wzYNDcuB/Xa3/qEY571PY+gf/FjlSXOR5HTJTHxftyJ8KZ3fRzs5z7uS8G26YOD9DqaywTKt+FXf+k9nwT7GY/7ErC7zsanUkpYc/zcdZQq+db3fQbs6x57JdhWPU8TjhPEeVs3Pmhx3eIJvfMP8J57wqP/J7DtvT2Ik6S0WtsZtKOJu+1f4z3nnHPXfdfXgG27erYURzgrt8Cej3f8tgl2Hb3xn78H7Ff+2PfjcZc2tpdaITgsSbde+VjO9Rq7ir7yn/0x2D/3uK8EuzKdQVcU9zmwTUm+JZ37//0n94P9nV++C/b+gT+HvQNu80FxksnxcZL/7WI4DtQ5vUkKIUQQLZJCCBFAi6QQQgTYWJOck5Z4OZrkxORul2U4wTWnHg2pyd0eduw8PsQzlufM260+1g7aIBxf3j/bIBd0RDpWYloNlNTOIqfv2lxY1veYjCaoNPm9/FPekz3nqgrnbu8doE7VdP6atS214x3kpvtxssg16te4PU+sbhrO9e1MWa51RHZaLJfHbuO2xTnbRpNMWU8+gjW1xpiVPsd6Np3AtsKNwM56bydt+P0maaj+gHkm0+L4c3DOud48g20THmfQbsQ8D+mgJS7nvfv5mnD7DWJ7jrnoReHnYjrFbWtK1q+NvUFlwwF6kxRCiABaJIUQIsDG7jaH7lh3m0ujsbtdGJcyVpmcS6lBZe7LqXIUy7bs2Q20Hf+45Bh1yLMuRcRNcM65ktywLPdzWbC7Ta5P1Xv3rBuUO0OyQVdGPw6Xe6sprMlWel6tY+42hlxUxsWuyd0mJQYKe4/5eIm+wnm3ZfRS2jGXrOtMSMl6FXbN2d1uzfUd1D+nf7AdDDmc6yiqCt3tkzPvNp7ePQXbugqflXphpKdIkXrX8IF6Oy9xW0YSV2vsOgtfI77nbPlC7sjJpQ4Lc0xFEn6OtmboUltlgqrmuSVVOV8Y+WjQGXMD9CYphBABtEgKIUQALZJCCBHgMto3UAqgCd8oqNtaTuEZVvJgzY3JKNUwN1oThxSwYmS1wy4iYA6aGRjBi7s9DlQM+w9pvGZ/Tt+xWk3C2ijpjva7eRG+XAmNY7s5VJT2tSDdcbEy5fBXYU1y/xD3VZtwlJo61RV0HUbGHE2xox9zxRzT8k4Z/Y5DyVLSzj6958OUyj3UUJmdCYbaHJi54bRT1qfxem2gd/HvzUXqqDtkS90FW6u1cddGomsxTAtCseicEnoa7O0ff14pZM9cB96W8/xchj7I6aG2JYzV+J1zbkytIEoTdhXr/ngUepMUQogAWiSFECKAFkkhhAiwsSY5HuhhJr2MWplmPaeTmW2R2DhOy7NxaANJg/QF21Z02EIV6amcUmY0ySwSG2aPY5MWlazN2KF70oM6jiuEEmaRODyK2WxMquWKUvz2D1D/Olj43L1FJC1x/5DbxNox8VwnJNnmZm4nWViTfPDODtgPO7N96TPH7RYljju7f//S56zYdyFOzjAdsOl83OSS4hp7vgmTIz8eS8LxnK3ff1VhvCZ3c62NrtxHpPC2xX31VivmuF/SBm0MNMdQMrzdPju8bdB+2YwbC2vOKC52Ymoojid4/Uak5RaFn6yWe+BugN4khRAigBZJIYQIsHkI0BjDJJytKt3gn9yTFu3MpCqlXPZ6AL2iG5vDL9qAHXODOUQIwovoGAd7sp7LBm/v7KL1AXedq870zrsKscpGXOlnufbX4WCJbuPhkkOA/I/XkZQ3Tj1sjH7AKWJ8yNZLHEdkjZ0R+pSnjYs9HeOtWxb43b2xr9y9Nw1fpN0JprwtbMRQj/dC0x7vfrM3eRQdPRvLlQ/VudijLNDXdH+b9MqyCM/dsjoEOzEhU0lDvjrNnZ2tJPK8spRkXVt+cDIKD8uNXMbPMlMWx6c0lrSK8TFnJuVRaYlCCPEFRoukEEIE0CIphBABkp6FPiGEEJfQm6QQQgTQIimEEAG0SAohRICN4yRvvO6xYPemxUFXLWBbR+lVmenaZz8759yL3vYRsG/6m9fiwEYx5RgnTjHquuPLVt30zjvAfvHf+Go8RptOxSXp3fF0dEy/cPsdg++85IdwrN6UP+OS/znHrEFMJXLDr34I7J99/FeBfe/Zg0ufL1K5sMMlxuutTMpbQyN98M4LYF/7UEwXbE2cZEuztUMheScKv+8vOz2Hba/7g7vA/vUn/hWwv/SML502ppYYXI7urgN/L9y1j+fzd9/+u2C/7HsfDfbdF/39fJFaO6xqnMfaxE1yjOtv3fFpx3z/1z4E7MKkkhaUVtpzWS8TCDuiGNJf/ch/BfunH/sVYM+3fArobI4xz9Mp2p25/h39yeL5b/33YN/05L8Kdt3YsmT0fNK+7LPDHUpf+66Pgf2cv/6VYBfm+nMLlGFsZ2o3wpaX//oHXQy9SQohRAAtkkIIEUCLpBBCBLiM3G0sR2Q1yZb6lbaUxJqalgxJHh4ypXJgnckR57JinGLcBVqBMj3pFiAtHl8N6y9s/y/dBvWxOtJBElv+jds/kC7Vmrz4qom0RqWWDIdLX2trucac45qSrO35cytQJqfWoDYfP6ffjqi98Cg3bT8iLQhcR+0MKq8HcmvW2pGWW/n7qEzCJeYmOZZsm438fdaQ5sz586mx+f48Cm7XUdf+GlVUG63nPGNjd5G2Icsa2zfk5tYoGsp75/p8lsj9ndK9YEsdcgtZrmGAmmT4XhhRgraVfxMu1UjtHHJTsi12bx+F3iSFECKAFkkhhAiweWVyqv7bWzeYKxCPMKTAdvHjjn7MZDIDu66NW0Xd5LoEX7N7E3KQRsqKDY4jsW4Tf5nKl9lq4Ru8vuflGGxwtzN0DVoqOX249iWvDg4xHIXZX+D2tXHl2p7K2VG4Sm6likgJswmVrUpMVXfbddI55+bkbk9SO8/hcS4u0P28x45JJcy4VPdB4uf8MHKJOrritizXpONHhFy51IbLRGrMOecmFK7SmudoEDJDIUAtuPaRbomDcBuz746OM+Rux54jqhVorwpfIv4H+wimEemlYJnOjsuV1nlX1pWPdEY4Cr1JCiFEAC2SQggRQIukEEIE2FiTHFEIEOgY3EmxRa0Q0oQi5eBHIyyl7xIf9tHRbzkFrku81pIEdZahJhlqjdBzmqLRFJMs0rbOOZeRRpuacvI9aWnczG1p2ipc2AtrkocLSpkDDZdCV+j8bSpmHtEkp5Q6mZvUSk4Rm5LWNLXhYmn4XjigkKbEpOW1FHvVdRQCVJpUyVH4GnUUulOazotTCh9KKdytMHMV69DpnHNzaoNi0xprag1RU/sG0CGjDT3xWPpQJ1FqKbFR28e//GrPIVH2GGhHAz3Q27G3tYK6qFr5l1tiBNucfA6FIfUmKYQQAbRICiFEAC2SQggRYGNNcqAlWnmBYw5Z87iMVKCU9DBbwixn/Y5i1qzGFWvvWY7Gx27jo+3pH2y4V5rGpzAvSM9N/HnUFc5VXaO+Uldel2tWqDkOxqH4t7nR1jqKV+wH+ZSmVFwe1vC2xjjvs5mfy+kU53VEIlBhxKRZRPvMKDa3NfdRQymaDYu5mYnjTTDekkky1D4L8+6QpNy6lu4581yMxuH0R+ece8Q1XwL2YuXbyC5Xe7DtcIGphQeH0Os2OE6ZswbtzzFxNX2b9L7e6qzBYag8oYNnfRBDPGjVbMaJnA+3ou6MNjy8i46/ty9LcP3LsS/7F0II8UWEFkkhhAiwubvN62kg/yiJhHaE4HS5zKQ8ZnQMOR0+hOZEXquLklInwU3A73Jgh01jY3fsKDJKS+zNfHVczaZG168xYTD1Et2vwThUDcWmDyYcpUVRH72Z2zzqbuPOTsz9+e3uYLXxnGYvMQPHZi6fYjiYrRTTJCg9VORSp8aF5nuKsa6oc84VphJVQVWp0pTkhJGXBLZ3t1yML73m4WDv7X/WfMbvnr+Ax52aELemwWNmihznPbPhcZzO21P1IXt/DnILEXa3IQU54eOndSKxbn3M3abUYKj4xZ0EwvblojdJIYQIoEVSCCECaJEUQogASR8TA4QQ4osYvUkKIUQALZJCCBFAi6QQQgTYOE7yl5/3ZPoXE3fVUtpXx2lPJq6Qtlz/uneDfcsz/newbbkvTkWrqLw9dPyjkW647X1gv/In/lc8QiPNcun7ltL9GmNzZ7aX/cq/dcwrnornlJq0xBW1KFgfYizk/vl7j/zsnHO/+pHzYP/kN+2CPRsfH7PGcZLOlAQbTTDe7zX/6r+A/eIfvBbs+cT/djbFzoM8UGvacXDs29N/7YNg//JTHoP7MpelWmOcZFPjPJYmDrakUnXXv/X9YN/6lG/DfZnYwLyguMgJxoFOpt6eb2Ea5fff8CbH/Pbrnwn2wcH9lz7vH5yFbfffh9f33nu9vVzhffLGf/0psJ/+nQ8BO8/8OW3N8ThtWqlzHCeJMbMvfNuHwX7l33wU/tbGGw+6alL8IsRJYrzl8//PD4D9qid/I9idKcfY881Mscu2WyunRr7w1/6Di6E3SSGECKBFUgghAmiRFEKIABtrks0g2deUKhq0qOS8Uqs3hMMy6wa1pdpoTVwOiw/J5pkmSTj/uCE9054f58VW1MrWltnPC9LgjmBdoX6WmzayHeu5lEdb5v64SPIacGKGms+2sTPShyhF3KVGW51uh3OQr37wabAL06KhpHYNdU051qaEWax9QzmjubXXtKAc/wqv92zi875nlAPO7O7g+a7N9S+pbcnWzjaOs+V/O57ES6XtnkD9rxzZ3+P93dBFWhz49h1dw6IywnUOElP+LKVnI6X89N6UTkv68HOUUEvkcNg15V+br/ZdeF3ouSRbD3+AoFG47cWxX90IvUkKIUQALZJCCBFgY3ebw2Kg+ji/CrP77eC9+vLGMXAIQZaxS2FCFwaVtxH2VlamJNmSw0vI3W6MnFBwRewjWFG4RpGbsCaqNt6s8bu5qSJdjsLndHIHXZ/TxrXjuVpTRfTelACb7syC45w6he5pbkqRFfTfLksNK3t+kc6Z2yfQtbVluJoKXWh2P6em8vx0fHwVeuec29nFsJ5V5SWPfIQu/2wL3U/j1busCLvAzjnXp1Rd3nZfpPngqve5kUSKPPzoDrZDcW4cp6dyaLZsXu/C7nbP71mmJQA/yWxDp8XLTI4O1hoPdUJQt0QhhPjCokVSCCECaJEUQogAm2uSgyYGAZ1x8Of843WKIaw7ZuYzbiuoJ0FrdMhVFdYKOQRoufba354JtXDOua5nrakz2+Ka5HK5wLGNhtdQR7yO9MtZ7vWx2TisSZ7aRe3tIQ/ymp5tg+GccweUDln3XnsbRWKNtnZRsxyV5rfUFmNNGutyaeY28l/0yStOgJ2b9LLAJXHOoSZXZuHbfIe0z3JlrhdJckVJA6X+fOo2fncvVxfBPlx6jfKQUlKrikPpbIuNcLgRd3XEMBic+KahkJnLaC7YcStR21aBWpZ+PlUZw7pj+CD7zzMGSG+SQggRQIukEEIE0CIphBABNtYkU4qzs45+zzGJpFPYMMqoLMGxYrbMGsfVkW2l0KYJa4UrauW6WHqN7pB0Qohlc87ZqegH4tiQ5QI1zsZMT08aZEIlv3ITpjebhFMgd3YwdvD0aa+1pTlpvft4TMvGi2/lHHVFZjzD7bO5H2c224FtrEmWC6/3JS48d7snd8EuYOI3byMak6FmO6jBZiNTNo+OMWMp0KRZtoP6c0MaSjttzP3T8jnkeL1HY3t9w+830xnqxp2JXeY2yD3NpS13NoiDJIbb7d8qNtcgOQZ6uD0wDqc78r7s+UiTFEKILyxaJIUQIsDG7vZoRH5GZ1KXUnRHu5oqe5vUPa4uzrDbZN+PW0p/7MheVX7fh4eU/kXs7x+AbcN06gpdooQq2/Q2FCkeAeSWB+xu+/0VdA4jOv9R4V3bGVfFIWYzDGUZz43rS+eQUfH4tDLuaSTlLSlwe2nc7fmpK3EbpXhmCzPvXAGJmG1humCW2HuHw0vo3jDhOHyfMPkE3xUmuZ/znseh2xOUpsg4zjlXTiid0gydljhWWqAMUBp3u1qSJEScOHUSbKimVeMzWFNqrU1F7CKpo+zq2rTiQXAQ/YONruIq5owNBXTOuc5oaz0dP1fhh31Hz2eI3iSFECKAFkkhhAigRVIIIQIk/eeTKySEEP+DozdJIYQIoEVSCCECaJEUQogAG8dJ3nbjU8C23ct6KtHfUYe82sRlVRSj9eyb3wP265/23WAnrS8XxWlfNe1rsfLBf2cvHsK2W977UbB/9FseAfbaxEZyyiJnZOYmxS+lOLp3fugex/zw15/B35vPsxzjv+YjvCQPvnJ+5GfnnPvxWz8E9u+86q+B/ZCH+li51mHZrfvPXQD7cO2vZzHD4/2up/0m2L/3qz8D9ukHPfzS5zPms3PONTXO5Wrpr0tfYwm5ax77DLDvfN8vgp32/r7qejyf3vG94bdzXOCXP+7vg/3xdz8H7MTG4JFi31IZwNZ8gQubXfuENzjmg7c/C4+zzcxnvNGqJXXtPKzMNoy9/RvPvw3st7/0SWCvFn7eF4c47wtKw21Nh8SOlogX/MrvgH3j3/p2/K1t3UKxqymVTstM7G5BcZI//yu/D/brfuJbcRzTUqWlDqvcwRFsipP8+bf+nouhN0khhAigRVIIIQJokRRCiAAba5IVlbyCPNWG8qRJI7A1zFjDY1JOhrZpl7wpPb7uUdeyQkSHSCXJEnNcI8pNLqjMWGF0xHSTfF0qtZ+bscZjzMeechmy3VOXPs9Pnw4PNMLte2vfzmFdoQ51DrsIuMrk2++U4dsiT6hFa+fno6K2GUlG5b7m3k57bE3LjE88CPfVWU0Sr1/XUYk5c126SAmzqZlj55xrTduEjvKCs47znO3G+OO0c/IKsCs7dx2V/qvxvmuN3azDtQmuejhq7ot9f8HP3Xcf7rc/C/ba1ECoBy0kEM6Zx64KyfHb6B+4TBzDR2GvaDeo94BrTGKuWaQi25HoTVIIIQJokRRCiACbu9tcQdtUVE46DPNIuQSWqS8Vr0Ac6LSY8us7V6P22ErMR9GQJGA78RXkbrP7PSpM2E4bd7dH5IZlIXd7jqW0Zrs+jGd++iHhgcbobl80YT2H+3i+58ndtqXFZlvh26JIUBLoTRjLeo3zMabzGc28nWfhe2G8exX+g3Gx25Y6WnZ8f/ZHfj6KyQ7Omy1D1lII07Asl+lgOA5XdHfOud2TGF61NuE2645aMzrcX+r8vdI1YTf4ymseCfbBBe9SNyQZLBYYLlebueyW4XJ27G47E8rDz+egvJ151rm5AdNwKJb5zO42LyE2pGug2W2A3iSFECKAFkkhhAigRVIIIQJsrEkmHLpjdR4Kt+ka6g1gNYNYYbaO9Uzzgy78486U968joTnrFvdlzyAbhCNQSIE5pk0mME9Ra5qY1MPdk1hm/8yVGI5y4ooHX/o8P/lgF6JPUf+7eM7rUIt9Sj2jaS5Mefwsco0S0nvrldcH+/192JYWqKuN5z4cKh9RKBFRzHBunLm+OWmQXYchMb3R7PqW70ckm+yCnTu/74T6XHBoGdyeCWuKQ+qO2qBkfg6KHOcjL/B6FsbuIyFuW6R92rTNcoZtIdKS7vfcpBxnYW2/T2m7bWhJ301YvzTPcyw0p+lo3m1adM9hWYHn93MoDKk3SSGECKBFUgghAmiRFEKIAJehSTImfpH0AkeaJCl6wXF6EstAx2BZlNtZGt2ljsTGrUlKsbFVKemVPdmu8cc0yeN5ThlpktOp14ROUKrhlVdfDfbJK3xs5NZJTNMbkKDWdPG81wpX+5iWWNJkllN/K+QxTZJi9GpTtmvVYgBmOeXUQ6N9lrPgOPnkBNipmeue0hJ70iTbyuuKDafU8hGNdsDue6+jsibZ0rm3Rhusm3gM3rLG95IiNZpkgS2BR5Mtsv32pA/rrPNd1HMbE1daTKk1MXcqNjdAn4a1z440SYiNpPuo6+mhg2c7fNO1rCuDDkmaJPf97T+/d0G9SQohRAAtkkIIEeBzdrehySJXRuEwCfvriHfK4SUQekTeTE+5TDZlrIuEC7EHnZsDS8g95mpDtlL5aBQP+9jaRjf4xGnv3p26CkM1Tj0YXerpfNcfRxlOe+NTrlfeBe0pvW40weOejbzPVUTSBflC2GvEhZmSQYUWP3l9H567vsfbE6tk07Vn6QVum/C90FNVo96cf9tQtXCa5NXau/2LBUoaR8EV4edbfg62Ury+5RjliCyzKX/hRzehcvo2OikpcK5Screzsd9eTMPvUcVkcME9LI8Nnl9jREL2khLXhb7xdkdV6XvaF64Fl/9eqDdJIYQIoEVSCCECaJEUQogASd9H/vYuhBBfxOhNUgghAmiRFEKIAFokhRAiwMZxkrf83A+AbctPdUssj9WtsRw8lnHHuKpn3vYfwf6lv/MosG3cXUPBjWvKmDp/6I/pU/fiMb3t/X8G9nd8FXatG5XjIz8759yMqlvNTNrWiS387mt+66OO+cW/9c1gX/lgP/bVj/xy2HbVw68Bu+/94H2Hl+trv/s6sN97ywvBvvNj/liSCq/JqR087p0dX4ZrvI3pcd/yzNvA/shbnw12Zkqa5TNMJdw6heXdts54ezTDdMDpVV8J9vIcXrPElHPrKC2voxYibb02nzEt8eTV3wT2/X/2ftyXSatdLnHeDvb3wN7b82mYFy6eg23f86QbHHP7W54P9pkz/l44fQbvyRMnrwR795RpZ0FtCGanvw7ss5/6XbDPn73r0udPfgLv0bv+/D+DvVj4FMbFEttkPOfVvw/2a5/3GLBdYuNgOb2X4xlNV0qKj37hGz4C9iuejudXm/jUekX3QoPxt23jnxuOrX7tO+5wMfQmKYQQAbRICiFEAC2SQggRYGNNclDKyORD9pTP2nXHt91MOLl3ALeJNTnVw9pLYKamRFKehNf/MkPdwraJHVM+9pTK289NrqvV8o7j1BWo0515kNeeTl6FOtQ26VKHF70mdnAxnBvcNVguLE/9dShGOB/zOeaTz7d9Wa5sGi5hlo3wt+XY2+UE5yOndrz2PmrqcBkuqzs551xvrmlDJfUaOnfUJHEbNYVwh4eou9naA8sl/nZB9qHR7/YPUAc/ir2DC2CPJ35+JhO8RpMp5nLXtb9GsceoqfGc7Pz0Pc57Qj1Yc3PJIuUCXDmiZ9+02Bi0VeAaD7YFQ6Q1cz5GzdLma3c914rgdcIayt0WQogvKFokhRAiwMbuNrvU1m5pW8MN1EzZpjQyZJdg3SYbPtSTW5BQGIStDjUdcbllZHdGZalKf1wFlZKaUyXn7akPy9k9ha70UZy+EsufnXqQrza+c+Yq2DalitL7ewvz+XxwnKbBUJfJ2MsGE6oCPjuxi+Oaro3ZFEOAmMkJDE3Jx3PzGcdJMrzerQn14NAcZkXhN41xydZrlB7WK7QrY9e07aEYaeTuvfsusG1HRA4targMoOnumcdKujvnRiMu6eaP7WBxH2wbH2KY1vTQzHMefo6aCufWlsrrG+4kQA9sY6SMyDXqa5zb3vi2wy6Gx3dcjckHBXVttMtEnuK7Xk2l/qwdqch2JHqTFEKIAFokhRAigBZJIYQI8DmHAHXGbildsGkoNMfoilkWLtnf0iHZ8CHWJHvWJM2uY5rkDoVX2NL4KWkaswnua2vHa0O7p04Fx3HOuZNXPYhs3xFx6xTqe+Mt1Dh7d/elz4f72ImQ6Ug/GhtNcj7DsJ3ZCRxndsq3kUgnmC7ITHYxTMllXqNNMszh7BKcy8roXV0kBGhxiCmAa9sq4RDDbZaHB/jdhbdXC9zG3Pfpu8G26XIpdcPMS3pkTLfAcgNNcjrh+9+f04pCnlbLbbL9OY+KcGxOW1P4lNVSBxok6ay21UeFIU8D1hQ+5RrzmTVJxEbpcbsJJk3wGIvC7y2na5SSRmnbr3RdLATxiLEv+xdCCPFFhBZJIYQIoEVSCCECbKxJppTm15l0wYZSilYVxpYlVgcgOYQ5XONvcys0kqjRchxWanSKIrz+T8Z46nXj91XT8acFpfCd8OW+ts98SXAc55zbOv1wsGcnvCZZjDnOErWmvvXnEdPweH6y3OuD5QTjF8fbOO5497Qfp5i7IGPcvlp6LXR5gLopt7ntzf/LLQWtXf3V+N3P3PnfwF6vvT62OEC9ckWapE1F5JhBZu/cPWDb9NdyhPfJeIqxi+XEz/FsHNbBnXPuNMWnWi0uIb1+OsHvFrm/D7OU6vcRBbWnLRL//YyuScKapLmezUFYz232MJa1601aouO/Ibhj7SQNP6/rC6h9Jvnxf0PIqCV0ZlI/obfuhuhNUgghAmiRFEKIAJfhbnN1Hk9LFYdX5Bb2rUktRE92wAFVGc4Lm7rEx0B+g3G3izLibpMb1ZqqMhUdf5pjZRvrbu9c8fDgOM45t3UGvzPd9amIxRhdefZJ7Nx1VczdpmouJhynGLjbmP443vHudp2iS8kk5G4v931q2rkL6G7XFIrSGdeOtzGfuQvd7dXKu1xLqrizJnc7MWE8rgtrPHtn0d3OjfvWknudJXjuo9Lb862ITOGG7nZn3OA+xXtySqFYeebvwyzinhYZuv6Fcc8zSs1L2d1eGXeb3GmGt0NlH/ouR9/YW72LVO1aUQWsfOTPJyfprJyQ1GDc7TQLyxRHoTdJIYQIoEVSCCECaJEUQogASc8tzYQQQlxCb5JCCBFAi6QQQgTQIimEEAE2jpO89ZmPB9vGuO1fxLYCh5Qy5kz8V09xSq9+xx+CfcOPPApsW1ptWOKd2jkYeZVLx7/0Nz4M9kuedC3uKfVxZV2KMWYPe+RXgP2Ir/jaS58f9NCHw7aveszj+CDdPZ/4CNizbR//1vcYw1evMYXukx/zx/2p/4T7+YHn/BLY73rF3wY7a3xc4e5pLOl21TWPAHvrtI/dXHV4W1zz6CeB/bH3/1Ow77n7TvMZWyG0DQXGmuvC26674S1g/x8vfTLYjSmz1tNve2qzYDPVMrpx/t6r3g32m3/++3AcE1dZUMm9mekq6ZxzW7v+Wp6kOf7WH7rRMXe87w1gFxO/v3KMpdHKEscalWY7xSaf/rJvA/uzH/0XYO+f9eXgPvmnfwTb7vqvfwL2xXP3Xvq8dw5bSrzoHefAfvkPYiyn/QsH/7mjHaQV+89cUu/V78Z42+f+dUyjzUxH05RinqcUr2qvWV7i9Xz6yz/gYuhNUgghAmiRFEKIAFokhRAiwMaaZEsl3zujifBKW1DpIuj1ytsGv+WfeuFikKvNdbjM9lhFpDHle85MK9fZiTOw7epHXAP2Q6552KXPJ6/A1gxHMd9F3caWMFsdoAa5olJjLWiU4X6YXYc5uK3R8Ljl6op049Qc0yKSIn7+XtQdP3vnn1/6fNefYb41503bvOiuD+dUn/3Mp8BOzPmPRniBR9RWoTA3UhFpv+p6bFGwWnotd12jht5SCxGX+3HG83ArXuecqxu8/8e5189mc7zvsgzzxlPTR7Vtw+XfmhqPs6pMKUDaVtNlsCUCVk34nls3/Aya0n6UrN3Sd+2uIyUd3MGSxqn9j5M1rU2UnG5LL/SXXylNb5JCCBFCi6QQQgTY2N3uyG3qoao0vt4OVl5bgTjSrCzlsJ5QmSsK87H7TtPwe3VR4KnvnPAu8ZmHPBi2nbkSuwNuG/e5jHRldM65hsI1bNe/JXVAPKRwqvXSl6Lq2rAf3NB2W517uUR3mzsv9mbyYu724iKGgSz3zpnPePwskYysnsKuK9FXWI3aXtKcKriPMuqyaUrgd23YZWwadLdrM2+OqqenK3S/lwtTlf0w7AI759whfacY+XthPMGJTxx+t2v9cbVUbf20QxYLkldMxf+6JTeY5rLu/Tmuu/BztOpx3lOrc9HDzrvqITQrvDAkGZYUhGYHJLu1XUq2/Ry+F45Cb5JCCBFAi6QQQgTQIimEEAE21iR7anMINldbY9tqBhEdijUg+OmgIDy3B/RCRRIRPzMKC5nPferS6SswFGN7m9PFTChGExHwnHMHF1H/Wy681rY6uIDb9lDvWyy8JtlExuJ2CI3pLrii1LzDPRy3M/puTIeqFtg6wepjCYUh5fTfcG6uSxYJB5tQPFhmdjYlLXhMdlX5c7ddFo+irnDebDuShN4jmhqDVSrbwfEw3OrAOef2L+LcJcmFS5/7njplknxmr39P+vPDaZw90pxX5jhr0uw60vvqxIceLTs8JmZNeqbtVMhdC1OKy8tNy4YsErM3mWMYXWPus4buuYTG7SFd+fIrQ+pNUgghAmiRFEKIAFokhRAiwMaa5CAlzgomJJ5wmbLU2DFJklMNQU+IaJK2zWYSablpUwOdcy41cXYptbdk3XFl2pe2PcarYbGsB9g7dxbshdEkqwWmB3JaYmXSEnlemZ7jxUyAWNOwlkYxiEajbSK3RVejxpcaTagg7dOmlTrnXGauWR7RjTm9NTcpgHmG14jL6HWdTcMLt64daL32nmONnL5bW01yH9vaHsXeOdSc29ofeL1C3Z9bNdegh4bvhXNn7wW7MTGnS9Zg6Xo3prRhm4dbsLYFasGJ0Y3TLKNtOI7VLFmvZEYzau1r7uespRRV0qdHpv1sMbr8vES9SQohRAAtkkIIEeAy3O3jXd2BG8ipP9bliv0JfhBO1JlN5IoPKpObkIJI5Ze8QDdif8+7vXf++Sdh2+QsusSTuXef8xLDJ77ka75jMNb5++4BuzNucUPVeZo1p6KZaktJRELIuBKOdzvy7HhXxznnMuP69pFxihx/a8NvZlN0izpy8226YB9JF0wG95X/LYftcNqs3d7GxqGUuMLMDc8FH3O98tfrsLsQHMc5587fi/fCcs+76AdjlGU6eo6a1s/lUHpC7rnzE2C3Zn5WK5RaqobkiNxIIrOwu51v4fwkuf1MacMZXqPUrAucjjwYZ4YyRwFZ0Xg/bp/Ae3D3lKn+Pgqfz1HoTVIIIQJokRRCiABaJIUQIkDSfy55OkII8UWC3iSFECKAFkkhhAigRVIIIQJsHCf5+qdi/B904tvHOML1AktGZfnoyM/OOfei2/8I7Buf8HVg9ya+q6NYqo5Ss7LSx0Bt7ezCtp99878D+83PfTzYrfOxVp3DuKtysgX2eOJLp01mWEbth59xk2Pec9sv4v4KW2qNUsRqjJNslr60VrPCef6h5/0jsG9/2Y+B3a38b0clntN8C89pNPXxnm2Ct8W3/9StYP/2rT8N9oX7fXzf+bMY61dTTF5jUhq59N0zbvsQ2Lde/41g2zS3hPMQ6b/72sSXNtTp81lvxnFef/1fBbs3cZMdxVByg87ODMxl1Z73j37fMa/5yW8Du8jLIz8/MBalKQaehefc8jtg/4OnfyfYtlVCn3D7BtzXYe1TYw8bvOde9+b/B+xnPe0RYLvCxPXS6pJzmqmJQc173Pby12Cc58ue+2U4jFm6ckppPHFyF+xTp09c+jwa4/rzfT9+u4uhN0khhAigRVIIIQJokRRCiACXkbtN9Me3SsgG5bLs50iOJm23+skge5y0M5u7nEZaVPZUhsqWEluThtVQnnC99Dpbt8bc66NYX7wP/2Hs9T8+Ds5BtjmtoxJzUpnZHPXRbOr1F9aDBjmsRh+q6fyZ5RJ1xtrmZ3PYLV0GuFciIbqs/9maAAnnl3c4kM1zz7mHBMF57aBJBjqRHHmMEfj+x1x2vM8GNRHsfEXK5jVUzq5L/Pc7OoY2peude128KMMtQ/IZ5ua3hckvTyn3POG/KZjfteFrVGVYhi43LSdyaj9RTqi2gHkOxuPwM3QUepMUQogAWiSFECLA5t0SA27F5bjb7E4PDii4bFPZKnK5oLp4cBQsQeYclrxarTAMp0oxpCnPTFhEFe+QtyJ3O63nlz73A1mA3OLSn9NoFO5cNyd3e2SubpqEq8dXxmWu67CEYLs9PvD9UAmvwPlFKpN3XBrPmCn5uRwSZN3xIrtMd9vsmt3plv4BSnyFT8c5Bw09H/hJbzog9lwhnc4JvO2wJNKSu133/hp1VLKszWncqf9uMYm423N0t/vcj9sm+Ns2UFIxrcOTtyZ3e1waOYVkqBG72xO520II8f8ZWiSFECKAFkkhhAhwGSFA1PnMaFzcCsBRl7QUtKewJslNDm0oR0J5TmlGHQ9NZ7c00i3RkaaTGcGnzFjfoo5/RmtJu3AnPuec6yvU8NrMhjXRcXKnxtTrKW2s0RtrwaVPc2OduOXzN3M5ScIl7rd2T4JtZbrVErWwnnQpm8YXCwEa6LXm6w23ZCA7N+07ItLnoH2D1Te5uyenUlrdtIuE5Tg3bMlgw62qmrslUqiOmcq6C2uFZy+iVt6l5p6dUDfTDO3C/N2gGIUnLyvpvjJzN7hE9A+dOfc0EgI0uN4mFTEvUKtPBxqzCemKX6IBepMUQogAWiSFECKAFkkhhAiwsSaZkCZpxZqUayKRJoCST6S9Jy3bVu/Mc9TK8gJjnlKjQ3H5pwGkydn4zKTEg2BVxsbG5S6sDTnnnGsw7rI1sl1PZZ4c6but0YfqyH9p3IkjNaW3UmoDy3GiuWkjOpuEdajd01eCva78HOxd3IdtXYJxdFh6LJI6ynGxVv/rOJ2T2peafac8x8RAkwyImHx/Ws0yErr4wHfoS4u117QPFqhvVxWe09rYTRse7L7zqEkmpf8+y4xUPcxl5m8K2Sg8d1mBE5KZdaLmUm+ksda1t7Mm/LzWfLomJbmgOMkkxXXCTlVTR9aFI9CbpBBCBNAiKYQQATZ2tzmkpu9sGAsReKPlqshHjARWkmZHfn7Apu+afScxt54O0maupTQOVxSyIU021OQ40vT43yccbsQVt43L0lTotjNNy+E2njxjqYJ8LONHxqIk8tEM7LGpzj7bwXAnHqcxVZOaOhw+lVGl7qb1rntL59o0aNvQsZSr3BAdpRrm9r4KF0AHN7+paxeDU14PD732sneA4VNVze6pGTcJXyWuZGXllBHd3xnlAttnPY28RyUdPZOdSQ1eU6gR2XllUkeT8HM0SaZo596elLjNHoNzzq0W/t6oPofXQr1JCiFEAC2SQggRQIukEEIESHqOGxFCCHEJvUkKIUQALZJCCBFAi6QQQgTYOE7y5qd9L9hd42PcqsVF2FYvMTUtyY6PdXze2/8E7H/w5G8AuzCpiByTyCWRIG6SOrVdf/P7wH7z0x+LvzUBcZyWNoibDJRpevJr3u2Y33zxj4BdlqaLIZ1TRumDlQmOsy0WnHPuh3/hbWC/940/A/bOyVOXPk+3sLVDOcZYx8TEUS6pO+TXf99Pgf0f3vVGsJcH/nqvDvHaV0tMj6uNvVpgSf4n33Q72G969nfjOIf++2vq2FhVGGM4MmXiyhJjRJ/9jz8I9i0/9Riwi8J/n++FQdsLc332DvBcX/hrf+yY5//AI8G+sL8+8rNzzrU9vsN0JuUvpXTA2//9nWD/6Hc8DOzR3P926xTec/OTaJczUzZwiud7wwv+C9gvvelLwa5Mimq1oljWNaXwmjTFaYnP0StfdxfYr3ghztsVJ31q7BWnrsDdUv7ueu3H4WzOH3/WP3Mx9CYphBABtEgKIUQALZJCCBFgY02yKKhMu/ncJOTo95TDalthcsk1gqM2bVptMyiHRfm6trtnrFIa7cuWZOM8dS4FZ1sdZFm41YFzziVUqsu2O81IVy1Ik7TtWttIbvCa8oIXC58nneZU4p7LzJnzr6rwOMsljmOnuhjRfh3nRZvfRWqL5ZS7beeRWztw5wTbKqBpwuPw9gTyvvG7fN/YfO2mirfy4Hx1W7Iu6bmeAJ5jASXMIrnOE7zeY9NmdVLib0d0D6amNURfRUoBLul5NrdGVpG2X+F3c3PPbWeT4DAnxyfA3hl7jX0+msO2fboOS6MVV+sN6tkRepMUQogAWiSFECLAxu42V6tuTOmlfk3Vp8nts2WdumjBcHxVti/7ScdlocmEcmfhkmw1vZL31rUbuMdcvswPtElS56Csl5kudqkyHspWbI50lFseYliMrRi+WOC2LQrNsZ0VDw4WLsS5e+6mg+yO/uzcoFx3Yku/NWFXjufWSgIsc2QZ7sv+tqnD46xXGHqDx0XdETuutu1tDg86irLAR253y8/7bEoyD1Xiz4ydFGHZ6sqTGPKVmtu7IIUop4eyX5vughEFoTugG3ZtrhE9r1mP352Y0KyTs53gOGd2T4G9Pfffn1E422Ifr1FtQpFWC7zWm6A3SSGECKBFUgghAmiRFEKIABtrktMpaZJGq2iXqPm0JWk8Rqqpu7BW2HWkb4KOQWEfFOdjpUNu7cBUg9AGU3aeftoPJEnTuiImsjrnWkonTIx2lXG4EQ3WmsnrYtEYB6RJNj5ddMTpghXqjoXRJA8Pw5rkxfvvOXYbX90sw/OzrRGaJhxqxG0VXCB0ijtpWu2QNWGGQ54SE9bTUzMLDgHaRIe0jEgQnE1siiqGPGUF2eYauYjmfnp3C+zehOl1KbX5aPH8m8bvO9KU0blDaqFi1gW+t0eUSjkvfNjPbkSTPL17EuyJ0SHHHM7WYbprvfLntzyUJimEEF9QtEgKIUQALZJCCBFgY01yewvjshqTYpRTC8cxlRazoUkLLpdEZBnqIzbEraO4qy4QKJlnYa2wa3G71a3qhnUL0qFM9GbbxlrkOldVGJPYmOPkeM2UWmvaWMd1ZO7291B3rDt/HnWDWljqcJ5HY6+N2ZS+o8h7PI7axBXWFJPYcbCjsdtIuuAhlR6zKXzc5nc0prQ2o0nG0h9HVKarsWl5pBFz2Tyrg+dZOHbROee25phCZ7VV1llteuQDg/uPfeT1ZkSxvZ3ZV0vn1NA93DemvXATPqe0IU3S7JvTHecT1Fh3515X3JphW1hmSmmWtusMxwAvFhinvVz4e321jAj7R6A3SSGECKBFUgghAmzsbm9t4Xra1v41fERpfBOqZJPt+1fjzkXc7RTdwMq4xTW9+nc9uQLWayjCbjCHNiTg+lGaVs8upN93yi7REbC7nRhfqevQVego9bCqvOtb1WE3+GB/D+zG5JTVFblFHbokjXFnCgo9YXKq8mSrgldUIagi97uuTWhOJHzqYJ9SJ0040WRMVW5GdMyhVEmiHJErZ9SWjn7L4WGZcbFHo3hFqPkcU+hsWmpG9xKHQFkVhMPSmJJChDrzPlSze012Z0KAkjp8f2ctyQ8mxG9MqaNbE3Spd7b8XGzPw1WAZlMM8zk49Pf2gkLWFofsbvvvrpbhsLOj0JukEEIE0CIphBABtEgKIUSApO83KfYlhBBfnOhNUgghAmiRFEKIAFokhRAiwMZxkn/0T54Adlv72KTVHpbzX+5hKa09E8a0h6Fv7rp/+Fmwb/3Jq3Ffax9rta64kyDHldkud7jtJe/4GNg3/cj/DHZuyurnOZfhohYLJl6PWzv8zJv+wDG3XP9osHsTS9ZR6TiO37Ql3dYUc/gLt38E7Jc94etoZL+zsqRY1inGFdo4w4xKdv29N/4u2P/42X8N7LVp37FaYZqljYt0zrnK2BwH+JLf/DDYL33io8C2HS3H4+OP/4HvHv3ZOeeuv+XfgH3z9f8LHbM/h0FpNEpRtdc/p4Ge+ZYPOObm678ZbJvKyL8PdQ7t6b576s3/Fuw3PeM76LhNOmjPLSiOTzPlONcXvvUPwX7VU74e7MQEK29vY1zkmTPYUuLkKV/Obb6D3/2mH3sr2H/8fz0V7Hvv9Sm4996H8cF3f/oC2Hd92pcMXCzw/nzLez/uYuhNUgghAmiRFEKIAFokhRAiwMaaZDlGTas1uaFNjjoNlzsrSlM+KZJ0OpmT5mMr1q+pXcMSv1ubPGcuccU0VLLeSpg99XXtOi4X5cdJBg0Ljhir5pL//jNXJeN85qo1edGDEm702x635/Y8uHQWDWxLnDVNOHR2SfnZdWPzsXG/bPfGjnU+4NYYnZl3LrNWJ1QToLTtZyP5x9nxj0HbhvU72yaiivXXcM4tqX1tYbTwgtrNDu4tuIaxNihcnMDkY9O7UZbiuDYdO1Jx0GXUjsLmoo+ovNlsG8vEzba8neXhkmx1hQdy4YL/Q8enP30Otn3ms1gy8N6z/g8hy5Vyt4UQ4guKFkkhhAiwsbudU6czWxo5KylEhqpWlYktnxR2E8b4Ru4S46omVIlqULjZnE2kQZ7LCvxCYqtK8yHSQKkdKFazyjnnUjpw60Ym6BZxiEmfdEd+PhLuHmk0BC7pxq6clScG1cSJeuCCGjeY3GsO87G7jibE8naza5YLuAOgjXJh+YQZdHg0oUYJH0PP52POvY6729UaQ1BsiBFLLSwT2KroSaRb4uAaWnc7YTeeXF1zHNyRlGlp9uxlYdWmp3uwN+9oVR0pm3eI83b/Od8R8a67z8O2z57F0mn3X/ASx7qKtX8cojdJIYQIoEVSCCECaJEUQogAG2uSCek6aW40SdIrc0qBK0xa32gUCwFCOzWaZFqgbpHmaOcmMoXbFTCjCZXlNwIYazYcIpJlvpR84uId8vIcS9NbHaqnUKTEUfdEE36U5eG5y3LWsGyaJpXZT7kzn7cjyqfrSYeyUhp3oeRKfJdVmG/wXRgIt/C4Rh6MdRbkOKw0OT50Kqd0196kwlaRdhTODbtJWh2ypuPgkCDbVSNlHZFgTdJKi5zSyJp7a75cDy8CsCIZtjUpjSPauKw6sv01bDgfl7i4j2Fn997nNclP3YWa5Ll9DLPaW/p91+3l3IAPoDdJIYQIoEVSCCECaJEUQogAG2uSg6BEYyekd2WspZjPMUVgTJ0l09L/IiNNkrPJbIZUtQ6PNJmRhmW0Ck6H46w2KMMWFbzcYO5s7NkgDG/wU6P95uHLxdppbnTHgSbJ/z9uEu9pfg0/tZ9ZdDw+XC86JocCWnuwjQZKnE1RjcXGsQpr40t5IE7ps2XzIsM4TMt0zrkmpLMGJi/24HLMZQqiJB0T/da2cV7F2hhTi9bV0uuBrHvvkq5YmAe25TRKHucQWy9fNPUXz50/gG1Wg3TOuaVpkfs5SJJ6kxRCiBBaJIUQIsDG7nZFVcG7xttdT7uhNLzMpNMVafj1vaQQodS8OWcZh2OgXZoQmaoM+z5b25ROZdKimoZT3DiVzLy+d/H/Z+oW06QaWzVnkOKHtk0fLNKxC1HS9ty42AO3kV0u4+7EvMaEyvdkZmfsQQ9SR13AZybyQUiTcTcpHIrt1NiRaJlB7iG4uQNvm8LDzM6LNv44FSP8TtP4uawbvvZ8mGaeI7FUHYfUmAvR9wGX32H17guH4cpT996PrQb2L/p7fbnA52hC1eRtGSgqhj+AK2C1tuISXT9eJ8apDW+7HFnpAfQmKYQQAbRICiFEAC2SQggRIOlj4oYQQnwRozdJIYQIoEVSCCECaJEUQogAG8dJ/uE/fQrYfevjo9rV3bCtrT6D381b8xljp77lOvzt7731IWDb7Kq2wTW9aSjmrDYdHKl2/Pc/58/AfserrwG7rvIjPzvnXFUVge9i3NUzbv2wY/7+372WjtOU7Kc8KW64l2d+7JzSvJ77a38A9uuvewzYkDJHsXDcTc/GBnJs4zNvw3He+He+GWyM+zy+M+RfDGTAuXver/9HsF/zY98Idmri37idCNs2LpQyCd1Tb30/2L/8U9927DEPy+ZxmTh/7us1xvI98y14Ps4594tP/hqwV6Z734paO3DLDVsKrygxsPDFv3EH2K+57lG4L1NnjVsuVBTcer/pRHj/RYzxfdtvfxzs7732arDPnfUpgid3MMf4yx95BdhXX71z6fNsC5+xp77i34D9lpd9F9h/8tG7Ln3+qPnsnHOrmtOAC/MZt33gE/e5GHqTFEKIAFokhRAigBZJIYQIsLEmebCHdtea/OU1rrUdaXrpyHwuw7nbXc3Jv14g4lTfMqP2DUZ86iK529tbeMy1yd2uKhQGKyo7X6399vU6ngs6naHWVBmzrvAcSHZ1mdXWonmnx5ebGrZROL41KrdnYLidqxXxBvnG/GPQ+CKl0khMtPogH2PTJfRdY0T6UXBJ/8QI4QnndVN+tS3D1lbhPOcHfo+lxWDeuY0C6citGbvrcT/McoXHktS2hQFOyKpBe+/C8sjPR3Gwj5rlauHHrcaoMzbcztWsIWUaTt6ejWZg70x9n5cTW9jzZYWPm2tMfYX+c3gv1JukEEIE0CIphBABNna398ndttWW2hW52zV1SzSv80WktBg1D3SZcakzcq8pIgZCV5JIGa6tLdxu3e26RreAIjPcemVCUSJuvXNDd9uGkQyrWVPJLxOekUQqeScJh/UcZwzLZYH7HSnfzNW1Q+52CA6vYbgsma3SziWvBqFG5hBjebc1hYulZm7SHqUXdnP7zttdE3aBnXOub/Be6E1l+57kBS6b15kSfg1LHsRqxa6/H3dFHRuXa7T3LqzM57C7fbjH7rafg2qK+22oynlv3O3iMt3t7am3T26ju71Y4bxVpjI537qboDdJIYQIoEVSCCECaJEUQogAG2uSrRuBbVWcNtnF71LYROq8NpFGQhfa7jTYSep/y6l1wy6Nfs3Py/D6P5nvgl0Yjacl4aIkTXJkwnZGq/j/MzuntsFerfxxj0jysXqnc865zl+ivg33IRhvb+E/9Ob7pGdyR8g+JGASo9kO2J2Zr472mzgOzbHpguG5G89x3qyASzLiIPips7pqFz6fJMX0ucSE9aS052zQqsRcH952BFlOLTiMRt+RXt9Tq5MkM1ppTM8tqO2ouQ45nVNBuut47I9jNgvfcydO7oI93/JzfcVpvH4nT58Ce+fEyUuft3dxP8zODv721CmvuV55JT6gB4e4xizX9tm+/MqQepMUQogAWiSFECKAFkkhhAiwsSbZZ6hx9M6nHHUpleGimKfWxO9x3BnT9leCnXQ+Zivl/DIqW5UZHbIYR/S72Umwe9cd+dm5YRydjalcr2P9Sp3bOY1jjY0muV7iObAm2ZqYUy4Vx0y3T4ANMXg9/TZQwizW0WOyhePYeL6W26KS7mh1yJgmOdnaBdtelZRESE4ttMfR1senazrnXEL3tr3PBvqdo/vXaOy9I/H6CLJ8imMHNEm+SJm5Lllk7rIRxg5abbjPKJ6W7Fnv//7QZeFUyzNX4N8Q0szfr2dOoXZ95sozYJ845X+7S9oms30Cf3vqjL8OB9S6drqPx2y3N83lB0rqTVIIIQJokRRCiAAbu9suwa/aiJI+ofCghNKPjMvSByrVOOdc35Nbb91A+i1HQVjXzr72H0VWUBoUhC2xW0/up5EXuHLLUZRjmh8TmtN3nF5H1ddtdfFIqmVG1ar77vgQIE4ghHmOhElkBZ6PS+z1RdeHXerMXJfo+eR4PlDYh8LMuGIOuK6RcJmE7u3EXH/+JR9yYiYuTeOuXJryWLZCDYVLBfcTOacMK/DYClIp3WMZuflF4c+pKMP3wniC90JR+HGnswl9F8Of7HNRlnRPEbx9NPb7mkxwnJoqidWtl0E4tXkT9CYphBABtEgKIUQALZJCCBEg6WPxHkII8UWM3iSFECKAFkkhhAigRVIIIQJokRRCiABaJIUQIoAWSSGECKBFUgghAmiRFEKIAFokhRAiwP8LQ9xuV58+8oEAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEncoder(tf.keras.layers.Layer):\n",
        "  def __init__(self, num_patches, projection_dim):\n",
        "    super().__init__()\n",
        "    self.num_patches = num_patches\n",
        "    self.projection = tf.keras.layers.Dense(units=projection_dim)\n",
        "    self.position_embedding = tf.keras.layers.Embedding(input_dim = num_patches, output_dim = projection_dim)\n",
        "\n",
        "  def call(self, patch):\n",
        "    positions = tf.range(start = 0, limit = self.num_patches, delta = 1)\n",
        "    encoded = self.projection(patch) + self.position_embedding(positions)\n",
        "    return encoded\n",
        ""
      ],
      "metadata": {
        "id": "BwK-cDYnyzoo"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_patches = 144\n",
        "projection = tf.keras.layers.Dense(64)\n",
        "position_embedding = tf.keras.layers.Embedding(144,64)"
      ],
      "metadata": {
        "id": "ID_FFRAc0gsq"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positions = tf.range(start = 0, limit = 144, delta = 1)\n",
        "positions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIQ3NfOD0rix",
        "outputId": "57214f37-6696-42b5-d9c7-aba10776f3d4"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(144,), dtype=int32, numpy=\n",
              "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
              "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
              "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
              "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
              "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
              "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
              "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
              "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
              "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
              "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
              "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
              "       143], dtype=int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "start : 시작\n",
        "limit : 최댓점\n",
        "delta : 증가량"
      ],
      "metadata": {
        "id": "xyPmpTS10y0B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "projection(patches).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXINE2l-0yDp",
        "outputId": "65ee9938-4205-4347-ebff-6a8c311eb8cc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([None, None, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "position_embedding(positions).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo8EV-Re0-GW",
        "outputId": "0989191f-7158-460c-8aeb-02102c8533f3"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([144, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BroadCasting\n",
        "encoded = projection(patches) + position_embedding(positions)\n",
        "encoded.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCBnjIEQ1Cnm",
        "outputId": "0e3ad86d-5258-41a8-8aeb-412e32ddb577"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 144, 64])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 최종"
      ],
      "metadata": {
        "id": "25vZvwto1T41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_patches = (72 // 6) ** 2\n",
        "num_patches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tyuvNbN1iRM",
        "outputId": "3be42593-dee1-46e0-a7ca-3dfbc00d74be"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
        "augmented = transform(inputs)\n",
        "patches = Patches(6)(augmented)\n",
        "encoded_patches = PatchEncoder(144,64)(patches)\n",
        "\n",
        "# Transformer block\n",
        "for _ in range(8):\n",
        "\n",
        "  x1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "  attention_output = tf.keras.layers.MultiHeadAttention(num_heads = 8, key_dim = 64, dropout=0.1)(x1,x1)\n",
        "  x2 = tf.keras.layers.Add()([attention_output, encoded_patches])\n",
        "  x3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(x2)\n",
        "  x3 = mlp(x3, hidden_units = [128, 64], dropout_rate = 0.1)\n",
        "  encoded_patches = tf.keras.layers.Add()([x3,x2])\n",
        "\n",
        "# MLP layer\n",
        "x = tf.keras.layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dropout(0.5)(x)\n",
        "x = mlp(x,hidden_units = [1024],dropout_rate=0.5)\n",
        "\n",
        "output = tf.keras.layers.Dense(10)(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs = output)"
      ],
      "metadata": {
        "id": "Ul9G9RWW1Pr0"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tv3_-zUa2lk3",
        "outputId": "224cf6b3-ede2-4c2a-d76b-4077125a6197"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 32, 32, 3)]  0           []                               \n",
            "                                                                                                  \n",
            " sequential (Sequential)        (None, 72, 72, 3)    7           ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " patches_3 (Patches)            (None, None, 108)    0           ['sequential[2][0]']             \n",
            "                                                                                                  \n",
            " patch_encoder_2 (PatchEncoder)  (None, 144, 64)     16192       ['patches_3[0][0]']              \n",
            "                                                                                                  \n",
            " layer_normalization_2 (LayerNo  (None, 144, 64)     128         ['patch_encoder_2[0][0]']        \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_1 (MultiH  (None, 144, 64)     132672      ['layer_normalization_2[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 144, 64)      0           ['multi_head_attention_1[0][0]', \n",
            "                                                                  'patch_encoder_2[0][0]']        \n",
            "                                                                                                  \n",
            " layer_normalization_3 (LayerNo  (None, 144, 64)     128         ['add_2[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_10 (Dense)               (None, 144, 128)     8320        ['layer_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 144, 128)     0           ['dense_10[0][0]']               \n",
            "                                                                                                  \n",
            " dense_11 (Dense)               (None, 144, 64)      8256        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 144, 64)      0           ['dense_11[0][0]']               \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 144, 64)      0           ['dropout_3[0][0]',              \n",
            "                                                                  'add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_4 (LayerNo  (None, 144, 64)     128         ['add_3[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_2 (MultiH  (None, 144, 64)     132672      ['layer_normalization_4[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 144, 64)      0           ['multi_head_attention_2[0][0]', \n",
            "                                                                  'add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_5 (LayerNo  (None, 144, 64)     128         ['add_4[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_12 (Dense)               (None, 144, 128)     8320        ['layer_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 144, 128)     0           ['dense_12[0][0]']               \n",
            "                                                                                                  \n",
            " dense_13 (Dense)               (None, 144, 64)      8256        ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 144, 64)      0           ['dense_13[0][0]']               \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 144, 64)      0           ['dropout_5[0][0]',              \n",
            "                                                                  'add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_6 (LayerNo  (None, 144, 64)     128         ['add_5[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_3 (MultiH  (None, 144, 64)     132672      ['layer_normalization_6[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " add_6 (Add)                    (None, 144, 64)      0           ['multi_head_attention_3[0][0]', \n",
            "                                                                  'add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_7 (LayerNo  (None, 144, 64)     128         ['add_6[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_14 (Dense)               (None, 144, 128)     8320        ['layer_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_6 (Dropout)            (None, 144, 128)     0           ['dense_14[0][0]']               \n",
            "                                                                                                  \n",
            " dense_15 (Dense)               (None, 144, 64)      8256        ['dropout_6[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_7 (Dropout)            (None, 144, 64)      0           ['dense_15[0][0]']               \n",
            "                                                                                                  \n",
            " add_7 (Add)                    (None, 144, 64)      0           ['dropout_7[0][0]',              \n",
            "                                                                  'add_6[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_8 (LayerNo  (None, 144, 64)     128         ['add_7[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " multi_head_attention_4 (MultiH  (None, 144, 64)     132672      ['layer_normalization_8[0][0]',  \n",
            " eadAttention)                                                    'layer_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " add_8 (Add)                    (None, 144, 64)      0           ['multi_head_attention_4[0][0]', \n",
            "                                                                  'add_7[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_9 (LayerNo  (None, 144, 64)     128         ['add_8[0][0]']                  \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " dense_16 (Dense)               (None, 144, 128)     8320        ['layer_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " dropout_8 (Dropout)            (None, 144, 128)     0           ['dense_16[0][0]']               \n",
            "                                                                                                  \n",
            " dense_17 (Dense)               (None, 144, 64)      8256        ['dropout_8[0][0]']              \n",
            "                                                                                                  \n",
            " dropout_9 (Dropout)            (None, 144, 64)      0           ['dense_17[0][0]']               \n",
            "                                                                                                  \n",
            " add_9 (Add)                    (None, 144, 64)      0           ['dropout_9[0][0]',              \n",
            "                                                                  'add_8[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_10 (LayerN  (None, 144, 64)     128         ['add_9[0][0]']                  \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_5 (MultiH  (None, 144, 64)     132672      ['layer_normalization_10[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " add_10 (Add)                   (None, 144, 64)      0           ['multi_head_attention_5[0][0]', \n",
            "                                                                  'add_9[0][0]']                  \n",
            "                                                                                                  \n",
            " layer_normalization_11 (LayerN  (None, 144, 64)     128         ['add_10[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_18 (Dense)               (None, 144, 128)     8320        ['layer_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_10 (Dropout)           (None, 144, 128)     0           ['dense_18[0][0]']               \n",
            "                                                                                                  \n",
            " dense_19 (Dense)               (None, 144, 64)      8256        ['dropout_10[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_11 (Dropout)           (None, 144, 64)      0           ['dense_19[0][0]']               \n",
            "                                                                                                  \n",
            " add_11 (Add)                   (None, 144, 64)      0           ['dropout_11[0][0]',             \n",
            "                                                                  'add_10[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_12 (LayerN  (None, 144, 64)     128         ['add_11[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_6 (MultiH  (None, 144, 64)     132672      ['layer_normalization_12[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 144, 64)      0           ['multi_head_attention_6[0][0]', \n",
            "                                                                  'add_11[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_13 (LayerN  (None, 144, 64)     128         ['add_12[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_20 (Dense)               (None, 144, 128)     8320        ['layer_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 144, 128)     0           ['dense_20[0][0]']               \n",
            "                                                                                                  \n",
            " dense_21 (Dense)               (None, 144, 64)      8256        ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 144, 64)      0           ['dense_21[0][0]']               \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 144, 64)      0           ['dropout_13[0][0]',             \n",
            "                                                                  'add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_14 (LayerN  (None, 144, 64)     128         ['add_13[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_7 (MultiH  (None, 144, 64)     132672      ['layer_normalization_14[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 144, 64)      0           ['multi_head_attention_7[0][0]', \n",
            "                                                                  'add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_15 (LayerN  (None, 144, 64)     128         ['add_14[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_22 (Dense)               (None, 144, 128)     8320        ['layer_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 144, 128)     0           ['dense_22[0][0]']               \n",
            "                                                                                                  \n",
            " dense_23 (Dense)               (None, 144, 64)      8256        ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 144, 64)      0           ['dense_23[0][0]']               \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 144, 64)      0           ['dropout_15[0][0]',             \n",
            "                                                                  'add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_16 (LayerN  (None, 144, 64)     128         ['add_15[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " multi_head_attention_8 (MultiH  (None, 144, 64)     132672      ['layer_normalization_16[0][0]', \n",
            " eadAttention)                                                    'layer_normalization_16[0][0]'] \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 144, 64)      0           ['multi_head_attention_8[0][0]', \n",
            "                                                                  'add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_17 (LayerN  (None, 144, 64)     128         ['add_16[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " dense_24 (Dense)               (None, 144, 128)     8320        ['layer_normalization_17[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 144, 128)     0           ['dense_24[0][0]']               \n",
            "                                                                                                  \n",
            " dense_25 (Dense)               (None, 144, 64)      8256        ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 144, 64)      0           ['dense_25[0][0]']               \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 144, 64)      0           ['dropout_17[0][0]',             \n",
            "                                                                  'add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " layer_normalization_18 (LayerN  (None, 144, 64)     128         ['add_17[0][0]']                 \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 9216)         0           ['layer_normalization_18[0][0]'] \n",
            "                                                                                                  \n",
            " dropout_18 (Dropout)           (None, 9216)         0           ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dense_26 (Dense)               (None, 1024)         9438208     ['dropout_18[0][0]']             \n",
            "                                                                                                  \n",
            " dropout_19 (Dropout)           (None, 1024)         0           ['dense_26[0][0]']               \n",
            "                                                                                                  \n",
            " dense_27 (Dense)               (None, 10)           10250       ['dropout_19[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 10,660,817\n",
            "Trainable params: 10,660,810\n",
            "Non-trainable params: 7\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['acc'])"
      ],
      "metadata": {
        "id": "EtfbJwxf3AN2"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, batch_size = 256, epochs = 100, validation_split=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "aJ2Bl0tF3GKk",
        "outputId": "d5e8af30-5063-4fa6-9865-49726e78c0fc"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "176/176 [==============================] - 69s 204ms/step - loss: 5.8628 - acc: 0.1357 - val_loss: 2.3695 - val_acc: 0.1046\n",
            "Epoch 2/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.5744 - acc: 0.1147 - val_loss: 2.4412 - val_acc: 0.1062\n",
            "Epoch 3/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3630 - acc: 0.0956 - val_loss: 2.4090 - val_acc: 0.0888\n",
            "Epoch 4/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3630 - acc: 0.0896 - val_loss: 2.3528 - val_acc: 0.0846\n",
            "Epoch 5/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3524 - acc: 0.0886 - val_loss: 2.3528 - val_acc: 0.0846\n",
            "Epoch 6/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3569 - acc: 0.0884 - val_loss: 2.3528 - val_acc: 0.0846\n",
            "Epoch 7/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3524 - acc: 0.0896 - val_loss: 2.3528 - val_acc: 0.0846\n",
            "Epoch 8/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3553 - acc: 0.0909 - val_loss: 2.3528 - val_acc: 0.0846\n",
            "Epoch 9/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3511 - acc: 0.0912 - val_loss: 2.3528 - val_acc: 0.0846\n",
            "Epoch 10/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3546 - acc: 0.0908 - val_loss: 2.3528 - val_acc: 0.0846\n",
            "Epoch 11/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3533 - acc: 0.0904 - val_loss: 2.3500 - val_acc: 0.0892\n",
            "Epoch 12/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3485 - acc: 0.0941 - val_loss: 2.3463 - val_acc: 0.0886\n",
            "Epoch 13/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3949 - acc: 0.0869 - val_loss: 2.6549 - val_acc: 0.0680\n",
            "Epoch 14/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.5791 - acc: 0.0872 - val_loss: 2.6139 - val_acc: 0.0880\n",
            "Epoch 15/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.5729 - acc: 0.0988 - val_loss: 2.6139 - val_acc: 0.0880\n",
            "Epoch 16/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.5772 - acc: 0.0977 - val_loss: 2.6139 - val_acc: 0.0880\n",
            "Epoch 17/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.5445 - acc: 0.0974 - val_loss: 2.3026 - val_acc: 0.1002\n",
            "Epoch 18/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3040 - acc: 0.0998 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 19/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.0998 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 20/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1002 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 21/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3028 - acc: 0.1011 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 22/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1026 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 23/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.0992 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 24/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1008 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 25/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1012 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 26/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3026 - acc: 0.1008 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 27/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3026 - acc: 0.0997 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 28/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.0995 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 29/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3026 - acc: 0.1019 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 30/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3025 - acc: 0.1009 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 31/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.0981 - val_loss: 2.3026 - val_acc: 0.0966\n",
            "Epoch 32/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3035 - acc: 0.0986 - val_loss: 2.3026 - val_acc: 0.0956\n",
            "Epoch 33/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3029 - acc: 0.0998 - val_loss: 2.3026 - val_acc: 0.0984\n",
            "Epoch 34/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1002 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 35/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1011 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 36/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1022 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 37/100\n",
            "176/176 [==============================] - 36s 204ms/step - loss: 2.3026 - acc: 0.1003 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 38/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3026 - acc: 0.1005 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 39/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3026 - acc: 0.1012 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 40/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3026 - acc: 0.1015 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 41/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.0994 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 42/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1032 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 43/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3026 - acc: 0.0998 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 44/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1009 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 45/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1007 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 46/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1014 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 47/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1018 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 48/100\n",
            "176/176 [==============================] - 36s 204ms/step - loss: 2.3026 - acc: 0.1033 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 49/100\n",
            "176/176 [==============================] - 36s 203ms/step - loss: 2.3026 - acc: 0.1008 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 50/100\n",
            "176/176 [==============================] - 35s 196ms/step - loss: 2.3026 - acc: 0.1012 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 51/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1004 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 52/100\n",
            "176/176 [==============================] - 35s 197ms/step - loss: 2.3026 - acc: 0.1012 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 53/100\n",
            "176/176 [==============================] - 34s 196ms/step - loss: 2.3026 - acc: 0.1014 - val_loss: 2.3026 - val_acc: 0.0986\n",
            "Epoch 54/100\n",
            " 50/176 [=======>......................] - ETA: 23s - loss: 2.3026 - acc: 0.1080"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-60-7dd5e7d397d3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1689\u001b[0m                             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1690\u001b[0m                             \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1691\u001b[0;31m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1692\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    473\u001b[0m         \"\"\"\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"end\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 322\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1091\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1167\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1168\u001b[0m             \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1169\u001b[0;31m             \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1170\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    678\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 680\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m         \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m         \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m         \u001b[0;31m# as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \"\"\"\n\u001b[1;32m   1159\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1160\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1161\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1125\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1126\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1127\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkBU2HWW3Qkb",
        "outputId": "e4f9e9a8-1c65-4ba8-df80-0ceebacc48c8"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 7s 22ms/step - loss: 2.3026 - acc: 0.1046\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.30259108543396, 0.10459999740123749]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1Vh7vxkM-fk9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}