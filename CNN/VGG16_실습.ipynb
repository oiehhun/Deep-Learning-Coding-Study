{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이토치 호출\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 토치비전 transform 및 데이터셋 가져오기\n",
    "from torchvision.transforms import transforms\n",
    "from torchvision.datasets import CIFAR10\n",
    "\n",
    "# 데이터 로더 가져오기\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "\n",
    "# 최적화 알고리즘 가져오기\n",
    "from torch.optim import optimizer\n",
    "\n",
    "# numpy\n",
    "import numpy as np\n",
    "\n",
    "# matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from PIL import image\n",
    "# import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드 고정\n",
    "torch.manual_seed(1) #CPU\n",
    "torch.cuda.manual_seed(1) #GPU\n",
    "torch.cuda.manual_seed_all(1)\n",
    "np.random.seed(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 transform 적용\n",
    "# 해상도는 논문에서 사용한 224*224 해상도 적용\n",
    "# transforms.Compose를 사용하여 여러 transform을 적용할 수 있음\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224,224)), # 224*224로 크기 조정\n",
    "    transforms.RandomHorizontalFlip(0.5), # 50% 확률로 좌우 반전\n",
    "    transforms.ToTensor(), # 텐서로 변환\n",
    "    transforms.Normalize((0.44671392, 0.43981278, 0.40664902), (0.061943434, 0.061971385, 0.06911716)) # 표준화를 원할 경우,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# 데이터 불러오기(fashion MNIST 사용)\n",
    "path = '/home/xogns5037/딥러닝코딩스터디/data/CIFAR10'\n",
    "\n",
    "train_data = CIFAR10(\n",
    "    root = path,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=data_transforms\n",
    ")\n",
    "\n",
    "test_data = CIFAR10(\n",
    "    root = path,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=data_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data[0].shape # 224 224로 resize가 필요함을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape : (50000, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# 이미지 정규화\n",
    "imgs = np.array([img.numpy() for img, _ in train_data])\n",
    "print(f'img shape : {imgs.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_r = np.min(imgs, axis=(2,3))[:, 0].min()\n",
    "min_g = np.min(imgs, axis=(2,3))[:, 1].min()\n",
    "min_b = np.min(imgs, axis=(2,3))[:, 2].min()\n",
    "\n",
    "max_r = np.max(imgs, axis=(2,3))[:, 0].max()\n",
    "max_g = np.max(imgs, axis=(2,3))[:, 1].max()\n",
    "max_b = np.max(imgs, axis=(2,3))[:, 2].max()\n",
    "\n",
    "mean_r = np.mean(imgs, axis=(2,3))[:, 0].mean()\n",
    "mean_g = np.mean(imgs, axis=(2,3))[:, 1].mean()\n",
    "mean_b = np.mean(imgs, axis=(2,3))[:, 2].mean()\n",
    "\n",
    "std_r = np.std(imgs, axis=(2,3))[:, 0].std()\n",
    "std_g = np.std(imgs, axis=(2,3))[:, 1].std()\n",
    "std_b = np.std(imgs, axis=(2,3))[:, 2].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : (-7.2116427, -7.09703, -5.8834743)\n",
      "max : (8.932118, 9.03945, 8.584714)\n",
      "mean : (0.7213963, 0.68330956, 0.57701886)\n",
      "std : (0.9696073, 0.979834, 0.9745563)\n"
     ]
    }
   ],
   "source": [
    "# 표준화 이전\n",
    "# STL10 데이터의 경우 정규화가 이미 잘 되어있는 데이터\n",
    "# 표준화가 나을지 정규화가 나을지는 직접 확인하며 작업해야함\n",
    "print(f'min : {min_r, min_g, min_b}')\n",
    "print(f'max : {max_r, max_g, max_b}')\n",
    "print(f'mean : {mean_r, mean_g, mean_b}')\n",
    "print(f'std : {std_r, std_g, std_b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min : (-7.2116427, -7.09703, -5.8834743)\n",
      "max : (8.932118, 9.03945, 8.584714)\n",
      "mean : (0.7213963, 0.68330956, 0.57701886)\n",
      "std : (0.9696073, 0.979834, 0.9745563)\n"
     ]
    }
   ],
   "source": [
    "# 표준화 이후\n",
    "# STL10 데이터의 경우 정규화가 이미 잘 되어있는 데이터\n",
    "# 표준화가 나을지 정규화가 나을지는 직접 확인하며 작업해야함\n",
    "print(f'min : {min_r, min_g, min_b}')\n",
    "print(f'max : {max_r, max_g, max_b}')\n",
    "print(f'mean : {mean_r, mean_g, mean_b}')\n",
    "print(f'std : {std_r, std_g, std_b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4  # 4개의 프로세스를 사용하여 데이터를 불러옴\n",
    ")\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset CIFAR10\n",
       "    Number of datapoints: 50000\n",
       "    Root location: /home/xogns5037/딥러닝코딩스터디/data/CIFAR10\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               Resize(size=(224, 224), interpolation=bilinear, max_size=None, antialias=warn)\n",
       "               RandomHorizontalFlip(p=0.5)\n",
       "               ToTensor()\n",
       "               Normalize(mean=(0.44671392, 0.43981278, 0.40664902), std=(0.061943434, 0.061971385, 0.06911716))\n",
       "           )"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data 개수 : 50000\n",
      "test data 개수 : 10000\n",
      "x shape (N, C, H, W): torch.Size([32, 3, 224, 224])\n",
      "y shape : (torch.Size([32]), torch.int64)\n"
     ]
    }
   ],
   "source": [
    "# 데이터 확인\n",
    "print(f'train data 개수 : {len(train_dataloader.dataset)}')\n",
    "print(f'test data 개수 : {len(test_dataloader.dataset)}')\n",
    "\n",
    "for x, y in test_dataloader:\n",
    "    print(f'x shape (N, C, H, W): {x.shape}')\n",
    "    print(f'y shape : {y.shape, y.dtype}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg16(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        # layer 1\n",
    "        # 224 * 224 * 3\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True), # inplace=True : 메모리 효율성을 늘리지 않기 위해 사용\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) #  112 * 112 * 64\n",
    "        )\n",
    "\n",
    "        # 112 * 112 * 64\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True), # 112 * 112 * 128\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 56 * 56 * 128\n",
    "        )\n",
    "\n",
    "        # 56 * 56 * 128\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True), # 56 * 56 * 256\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 28 * 28 * 256\n",
    "        )\n",
    "\n",
    "        # 28 * 28 * 256\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True), # 28 * 28 * 512\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 14 * 14 * 512\n",
    "        )\n",
    "\n",
    "        # 14 * 14 * 512\n",
    "        self.layer5 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(in_channels=512, out_channels=512, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(inplace=True), # 14 * 14 * 512\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2) # 7 * 7 * 512\n",
    "        )\n",
    "\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(in_features=7 * 7 * 512, out_features=4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(in_features=4096, out_features=4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "        )\n",
    "\n",
    "        self.fc3 = nn.Sequential(\n",
    "            nn.Linear(in_features=4096, out_features=10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "\n",
    "        # flatten\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        # fc\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vgg16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vgg16(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc3): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vgg16(\n",
       "  (layer1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (3): ReLU(inplace=True)\n",
       "    (4): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (1): ReLU(inplace=True)\n",
       "  )\n",
       "  (fc3): Sequential(\n",
       "    (0): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr= 0.001\n",
    "optimizer  = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.CrossEntropyLoss() # softmax + cross entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CrossEntropyLoss()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.304377794265747\n",
      "학습종료!\n"
     ]
    }
   ],
   "source": [
    "# 학습\n",
    "num_epochs = 1 # 에폭 설정\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        #Forward pass\n",
    "        outputs = model(images) # 모델 예측 시행\n",
    "        loss = criterion(outputs, labels) # 예측에 따른 손실 계산 및 출력\n",
    "\n",
    "        # backward pass\n",
    "        optimizer.zero_grad() # 가중치 변화를 0으로 만들고\n",
    "        loss.backward() # 역전파를 수행하고\n",
    "        optimizer.step() # 가중치를 갱신\n",
    "\n",
    "    print(loss.item())\n",
    "\n",
    "print('학습종료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "th",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
