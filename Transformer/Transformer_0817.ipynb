{"cells":[{"cell_type":"markdown","metadata":{"id":"QUflULi3Mtft"},"source":["# Sentencepiece: \n","데이터 전처리 부분이니 필요하신 분은 보세요~"]},{"cell_type":"markdown","metadata":{"id":"YoqslFezMLic"},"source":["## Sentencepiece"]},{"cell_type":"markdown","metadata":{"id":"sTEHJhl6M-Q8"},"source":["### 말뭉치 만들기(한국어 wiki)"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":298,"status":"ok","timestamp":1691828394749,"user":{"displayName":"정민화(일반대학원 디지털애널리틱스 융합협동과정)","userId":"16731830858174153458"},"user_tz":-540},"id":"IuCPv3DrOhR2"},"outputs":[],"source":["import os\n","os.chdir('/home/minalang/0817_transformer/web-crawler')"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19695,"status":"ok","timestamp":1691833407990,"user":{"displayName":"정민화(일반대학원 디지털애널리틱스 융합협동과정)","userId":"16731830858174153458"},"user_tz":-540},"id":"FMqWEwmrL6Sh","outputId":"65657bb9-e072-4c51-9c92-0332f783b362"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'web-crawler'...\n"]},{"name":"stdout","output_type":"stream","text":["remote: Enumerating objects: 75, done.\u001b[K\n","remote: Counting objects: 100% (75/75), done.\u001b[K\n","remote: Compressing objects: 100% (51/51), done.\u001b[K\n","remote: Total 75 (delta 36), reused 56 (delta 20), pack-reused 0\u001b[K\n","Unpacking objects: 100% (75/75), done.\n","Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25ldone\n","\u001b[?25hBuilding wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9674 sha256=06381b8b2ce118ddebb0e53a5401bff4082d33e6db9852bf0b70bd153a320ecf\n","  Stored in directory: /home/minalang/.cache/pip/wheels/e1/e8/db/ebe4dcd7d7d11208c1e4e4ef246cea4fcc8d463c93405a6555\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","Collecting pymongo\n","  Downloading pymongo-4.4.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.5/586.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0\n","  Downloading dnspython-2.3.0-py3-none-any.whl (283 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m283.7/283.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: dnspython, pymongo\n","Successfully installed dnspython-2.3.0 pymongo-4.4.1\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n","python: can't open file 'kowiki.py': [Errno 2] No such file or directory\n"]}],"source":["! git clone https://github.com/paul-hyun/web-crawler.git\n","! cd web-crawler\n","! pip install wget\n","! pip install pymongo\n","! python kowiki.py"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15,"status":"ok","timestamp":1691828333555,"user":{"displayName":"정민화(일반대학원 디지털애널리틱스 융합협동과정)","userId":"16731830858174153458"},"user_tz":-540},"id":"reC2GKocU9lg","outputId":"8b686474-700d-4384-d5d3-da26a94bc4da"},"outputs":[{"data":{"text/plain":["131072"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["# csv 최대 field 크기 늘리기\n","import sys\n","import csv\n","\n","csv.field_size_limit(sys.maxsize)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"elapsed":416,"status":"error","timestamp":1691828398999,"user":{"displayName":"정민화(일반대학원 디지털애널리틱스 융합협동과정)","userId":"16731830858174153458"},"user_tz":-540},"id":"tTLOqpu9MwBO","outputId":"974edf3a-4429-4290-b096-7bcefc8e45e3"},"outputs":[],"source":["# csv -> txt 파일로 변환\n","import pandas as pd\n","\n","in_file = \"/home/minalang/0817_transformer/web-crawler/kowiki/kowiki_20230812.csv\"\n","out_file = \"/home/minalang/0817_transformer/web-crawler/kowiki.txt\"\n","SEPARATOR = u\"\\u241D\"\n","df = pd.read_csv(in_file, sep=SEPARATOR, engine=\"python\")\n","with open(out_file, \"w\") as f:\n","  for index, row in df.iterrows():\n","    f.write(row[\"text\"]) # title 과 text를 중복 되므로 text만 저장 함\n","    f.write(\"\\n\\n\\n\\n\") # 구분자"]},{"cell_type":"markdown","metadata":{"id":"IlSnnxgiVXuf"},"source":["## SentencePiece"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4251,"status":"ok","timestamp":1663754851336,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"PDU-eS93OW5Q","outputId":"dd316351-895f-435f-a407-0f9711f8d7ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentencepiece in /home/minalang/.conda/envs/venv/lib/python3.7/site-packages (0.1.96)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"markdown","metadata":{"id":"voe9d29vVgs2"},"source":["## Vocab 만들기"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"ohIPzo3kVbpm"},"outputs":[{"name":"stderr","output_type":"stream","text":["sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/home/minalang/0817_transformer/web-crawler/kowiki.txt --model_prefix=/home/minalang/0817_transformer/web-crawler/kowiki --vocab_size=8007 --model_type=bpe --max_sentence_length=999999 --pad_id=0 --pad_piece=[PAD] --unk_id=1 --unk_piece=[UNK] --bos_id=2 --bos_piece=[BOS] --eos_id=3 --eos_piece=[EOS] --user_defined_symbols=[SEP],[CLS],[MASK]\n","sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n","trainer_spec {\n","  input: /home/minalang/0817_transformer/web-crawler/kowiki.txt\n","  input_format: \n","  model_prefix: /home/minalang/0817_transformer/web-crawler/kowiki\n","  model_type: BPE\n","  vocab_size: 8007\n","  self_test_sample_size: 0\n","  character_coverage: 0.9995\n","  input_sentence_size: 0\n","  shuffle_input_sentence: 1\n","  seed_sentencepiece_size: 1000000\n","  shrinking_factor: 0.75\n","  max_sentence_length: 999999\n","  num_threads: 16\n","  num_sub_iterations: 2\n","  max_sentencepiece_length: 16\n","  split_by_unicode_script: 1\n","  split_by_number: 1\n","  split_by_whitespace: 1\n","  split_digits: 0\n","  treat_whitespace_as_suffix: 0\n","  allow_whitespace_only_pieces: 0\n","  user_defined_symbols: [SEP]\n","  user_defined_symbols: [CLS]\n","  user_defined_symbols: [MASK]\n","  required_chars: \n","  byte_fallback: 0\n","  vocabulary_output_piece_score: 1\n","  train_extremely_large_corpus: 0\n","  hard_vocab_limit: 1\n","  use_all_vocab: 0\n","  unk_id: 1\n","  bos_id: 2\n","  eos_id: 3\n","  pad_id: 0\n","  unk_piece: [UNK]\n"]}],"source":["import sentencepiece as spm\n","\n","corpus = \"/home/minalang/0817_transformer/web-crawler/kowiki.txt\"\n","prefix = \"/home/minalang/0817_transformer/web-crawler/kowiki\"\n","vocab_size = 8000\n","spm.SentencePieceTrainer.train(\n","    f\"--input={corpus} --model_prefix={prefix} --vocab_size={vocab_size + 7}\" +\n","    \" --model_type=bpe\" +\n","    \" --max_sentence_length=999999\" + # 문장 최대 길이\n","    \" --pad_id=0 --pad_piece=[PAD]\" + # pad (0)\n","    \" --unk_id=1 --unk_piece=[UNK]\" + # unknown (1)\n","    \" --bos_id=2 --bos_piece=[BOS]\" + # begin of sequence (2)\n","    \" --eos_id=3 --eos_piece=[EOS]\" + # end of sequence (3)\n","    \" --user_defined_symbols=[SEP],[CLS],[MASK]\") # 사용자 정의 토큰"]},{"cell_type":"markdown","metadata":{"id":"Su7cCbkNVl5G"},"source":["- input: 입력 corpus\n","- prefix: 저장할 모델 이름\n","- vocab_size: vocab 개수 (기본 8,000에 스페셜 토큰 7개를 더해서 8,007개)\n","- max_sentence_length: 문장의 최대 길이\n","- pad_id, pad_piece: pad token id, 값\n","- unk_id, unk_piece: unknown token id, 값\n","- bos_id, bos_piece: begin of sentence token id, 값\n","- eos_id, eos_piece: end of sequence token id, 값\n","- user_defined_symbols: 사용자 정의 토큰"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1663500769234,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"GCDMymctVr5N","outputId":"e04cb3de-4889-48ea-b617-4c456965fdd1"},"outputs":[{"name":"stdout","output_type":"stream","text":["겨울이 되어서 날씨가 무척 추워요.\n","['▁겨울', '이', '▁되어', '서', '▁날', '씨', '가', '▁무', '척', '▁추', '워', '요', '.']\n","[3220, 3632, 681, 3646, 718, 4082, 3643, 107, 4235, 199, 4001, 3802, 3634]\n","\n","이번 성탄절은 화이트 크리스마스가 될까요?\n","['▁이번', '▁성', '탄', '절', '은', '▁화', '이트', '▁크리스', '마', '스가', '▁될', '까', '요', '?']\n","[2927, 90, 4013, 3968, 3648, 270, 645, 1900, 3706, 713, 1447, 3841, 3802, 4320]\n","\n","겨울에 감기 조심하시고 행복한 연말 되세요.\n","['▁겨울', '에', '▁감', '기', '▁조', '심', '하', '시', '고', '▁행', '복', '한', '▁연', '말', '▁되', '세', '요', '.']\n","[3220, 3635, 192, 3650, 54, 3879, 3640, 3657, 3645, 251, 3918, 3647, 62, 3878, 475, 3726, 3802, 3634]\n","\n"]}],"source":["# test\n","vocab_file = \"/home/minalang/0817_transformer/web-crawler/kowiki.model\"\n","vocab = spm.SentencePieceProcessor()\n","vocab.load(vocab_file)\n","\n","lines = [\n","  \"겨울이 되어서 날씨가 무척 추워요.\",\n","  \"이번 성탄절은 화이트 크리스마스가 될까요?\",\n","  \"겨울에 감기 조심하시고 행복한 연말 되세요.\"\n","]\n","for line in lines:\n","  pieces = vocab.encode_as_pieces(line) # 처리된 단어\n","  ids = vocab.encode_as_ids(line) # 처리된 index\n","  print(line)\n","  print(pieces)\n","  print(ids)\n","  print()"]},{"cell_type":"markdown","metadata":{"id":"nsid93zXX7BT"},"source":["# Naver 영화 review data"]},{"cell_type":"markdown","metadata":{"id":"0LSvjzLvYEMX"},"source":["## Download"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":62048,"status":"ok","timestamp":1663513647323,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"R1DKcyxAX1Kf","outputId":"c3f7674e-1a3c-46a6-f01c-668777920dd4"},"outputs":[{"name":"stdout","output_type":"stream","text":["--2023-08-12 19:16:01--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 14628807 (14M) [text/plain]\n","Saving to: ‘ratings_train.txt’\n","\n","100%[======================================>] 14,628,807  10.1MB/s   in 1.4s   \n","\n","2023-08-12 19:16:04 (10.1 MB/s) - ‘ratings_train.txt’ saved [14628807/14628807]\n","\n","--2023-08-12 19:16:04--  https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 4893335 (4.7M) [text/plain]\n","Saving to: ‘ratings_test.txt’\n","\n","100%[======================================>] 4,893,335   9.39MB/s   in 0.5s   \n","\n","2023-08-12 19:16:05 (9.39 MB/s) - ‘ratings_test.txt’ saved [4893335/4893335]\n","\n"]}],"source":["! wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\n","! wget https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt"]},{"cell_type":"markdown","metadata":{"id":"vAQ0rwIUYJGp"},"source":["## Vocab"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: sentencepiece in /home/minalang/.conda/envs/venv/lib/python3.7/site-packages (0.1.96)\n","\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2.1\u001b[0m\n","\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"]}],"source":["!pip install sentencepiece"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1663513647324,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"iBr9f_0zYFr0","outputId":"59e1859e-752a-4fc1-fadf-e6054b44b978"},"outputs":[{"data":{"text/plain":["True"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["vocab_file = \"./kowiki.model\"\n","vocab = spm.SentencePieceProcessor()\n","vocab.load(vocab_file)"]},{"cell_type":"markdown","metadata":{"id":"0oe9O9cZYNUf"},"source":["## Data preprocessing"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Lu8aK4X0YMOM"},"outputs":[],"source":["\"\"\" train data 준비 \"\"\"\n","def prepare_train(vocab, infile, outfile):\n","    df = pd.read_csv(infile, sep=\"\\t\", engine=\"python\")\n","    with open(outfile, \"w\") as f:\n","        for index, row in df.iterrows():\n","            document = row[\"document\"]\n","            if type(document) != str:\n","                continue\n","            instance = { \"id\": row[\"id\"], \"doc\": vocab.encode_as_pieces(document), \"label\": row[\"label\"] }\n","            f.write(json.dumps(instance))\n","            f.write(\"\\n\")"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"qdM889TwYSvu"},"outputs":[],"source":["import pandas as pd\n","import json\n","prepare_train(vocab, \"./ratings_train.txt\", \"./ratings_train.json\")\n","prepare_train(vocab, \"./ratings_test.txt\", \"./ratings_test.json\")"]},{"cell_type":"markdown","metadata":{"id":"xCDyIN4IYroQ"},"source":["# Transformer"]},{"cell_type":"markdown","metadata":{"id":"wANp6oGAYsru"},"source":["## Vocab"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"za1BfwvkYxPb"},"outputs":[],"source":["import torch\n","import sentencepiece as spm"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":597,"status":"ok","timestamp":1663754863182,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"h4LTKnl4Yjdz","outputId":"b8dd3aa0-d151-4807-a12a-5e61acc2aa76"},"outputs":[{"name":"stdout","output_type":"stream","text":["['▁겨울', '은', '▁추', '워', '요', '.']\n","['▁감', '기', '▁조', '심', '하', '세', '요', '.']\n","torch.Size([2, 8])\n","tensor([[3220, 3648,  199, 4001, 3802, 3634,    0,    0],\n","        [ 192, 3650,   54, 3879, 3640, 3726, 3802, 3634]])\n"]}],"source":["# vocab loading\n","vocab_file = \"./kowiki.model\"\n","vocab = spm.SentencePieceProcessor()\n","vocab.load(vocab_file)\n","\n","# 입력 texts\n","lines = [\n","  \"겨울은 추워요.\",\n","  \"감기 조심하세요.\"\n","]\n","\n","# text를 tensor로 변환\n","inputs = []\n","for line in lines:\n","  pieces = vocab.encode_as_pieces(line)\n","  ids = vocab.encode_as_ids(line)\n","  inputs.append(torch.tensor(ids))\n","  print(pieces)\n","\n","# 입력 길이가 다르므로 입력 최대 길이에 맟춰 padding(0)을 추가 해 줌\n","inputs = torch.nn.utils.rnn.pad_sequence(inputs, batch_first=True, padding_value=0)\n","# shape\n","print(inputs.size())\n","# 값\n","print(inputs)"]},{"cell_type":"markdown","metadata":{"id":"a74SdiO9ZaDd"},"source":["## Embedding"]},{"cell_type":"markdown","metadata":{"id":"YzSwVQ31Zcb2"},"source":["Input Embedding + Position Embedding"]},{"cell_type":"markdown","metadata":{"id":"d0LE1HWgZe_e"},"source":["### Input Embedding"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"LuL-jpXyZmyi"},"outputs":[],"source":["import torch.nn as nn"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":327,"status":"ok","timestamp":1663754879297,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"_9feL1LAZukJ","outputId":"2ead7775-05f8-4b64-8227-7c96c5545dbe"},"outputs":[{"data":{"text/plain":["8007"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["len(vocab)"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":335,"status":"ok","timestamp":1663754892252,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"mjlTGFqGYzF5","outputId":"f5b597b8-c1f7-4277-add7-213cdcbdb729"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 128])\n"]}],"source":["# inputs에 대한 embedding 값 input_embs 구하기\n","\n","n_vocab = len(vocab) # vocab count\n","d_hidn = 128 # hidden size -> 논문에서는 512차원\n","nn_emb = nn.Embedding(n_vocab, d_hidn) # embedding 객체\n","\n","input_embs = nn_emb(inputs) # input embedding\n","print(input_embs.size())"]},{"cell_type":"markdown","metadata":{},"source":["input embedding (2, 8)에 대해 input_embeds(2, 8, 128)차원을 가짐"]},{"cell_type":"markdown","metadata":{"id":"M1XIbITKZ27d"},"source":["### Position Embedding\n","- 각 position별로 angle값을 구하기\n","- 구해진 angle 중 짝수 index의 값에 대한 sin값을 구하기\n","- 구해진 angle 중 홀수 index의 값에 대한 cos값을 구하기"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"XlBFP4fdZ6e6"},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":32,"metadata":{"id":"v8awUxlxZmK8"},"outputs":[],"source":["def cal_angle(position, i_hidn): # hidden node index의 위치함수\n","        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n","def get_posi_angle_vec(position): # position을 매겨줌\n","        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n","\n","def get_sinusoid_encoding_table(n_seq, d_hidn): # 위치에 대한 sin, cos값을 매겨줌\n","    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n","    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin (64, 64)\n","    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos (64, ,64)\n","\n","    return sinusoid_table"]},{"cell_type":"code","execution_count":33,"metadata":{"id":"Ud9ZfyhN93JB"},"outputs":[],"source":["n_seq = 64\n","pos_encoding = get_sinusoid_encoding_table(n_seq, d_hidn)"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["(64, 128)"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["pos_encoding.shape # embedding dim과 같은 차원이어야함, position 64까지를 커버할 수 있음"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663510759733,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"J6GEkgsM97FY","outputId":"e47dab58-9bb9-4390-9b0a-d2f819dd371a"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[ 0.00000000e+00  1.00000000e+00  0.00000000e+00 ...  1.00000000e+00\n","   0.00000000e+00  1.00000000e+00]\n"," [ 8.41470985e-01  5.40302306e-01  7.61720408e-01 ...  9.99999991e-01\n","   1.15478198e-04  9.99999993e-01]\n"," [ 9.09297427e-01 -4.16146837e-01  9.87046251e-01 ...  9.99999964e-01\n","   2.30956395e-04  9.99999973e-01]\n"," ...\n"," [-9.66117770e-01 -2.58101636e-01  5.50740698e-01 ...  9.99966915e-01\n","   7.04411185e-03  9.99975190e-01]\n"," [-7.39180697e-01  6.73507162e-01 -2.78961912e-01 ...  9.99965822e-01\n","   7.15958714e-03  9.99974370e-01]\n"," [ 1.67355700e-01  9.85896582e-01 -9.12222820e-01 ...  9.99964710e-01\n","   7.27506233e-03  9.99973536e-01]]\n"]}],"source":["print(pos_encoding)"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663511071668,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"SUeC4VkM-mac","outputId":"836ff6c9-02b3-43ae-dfd2-7aabc8ba248b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Embedding(64, 128)\n"]}],"source":["pos_encoding = torch.FloatTensor(pos_encoding) #Tensor 생성\n","nn_pos = nn.Embedding.from_pretrained(pos_encoding, freeze=True) # freeze : 학습 과정동안 update 방지\n","print(nn_pos)"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663511256071,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"gKXIoOso9xAC","outputId":"a48db5fb-414f-46f4-ce7a-1cff15cc20ee"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[1, 2, 3, 4, 5, 6, 7, 8],\n","        [1, 2, 3, 4, 5, 6, 7, 8]])\n","torch.Size([2, 8])\n","tensor([[False, False, False, False, False, False,  True,  True],\n","        [False, False, False, False, False, False, False, False]])\n"]}],"source":["positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n","pos_mask = inputs.eq(0) #0과 같은지 아닌지\n","print(positions) # 문장 단어들의 위치정보\n","print(inputs.size())\n","print(pos_mask) # mask인지 아닌지 판별"]},{"cell_type":"code","execution_count":46,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663511314127,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"btmzGonn_Ys4","outputId":"d460e03d-76bf-4d4a-e140-71b91917d853"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[3220, 3648,  199, 4001, 3802, 3634,    0,    0],\n","        [ 192, 3650,   54, 3879, 3640, 3726, 3802, 3634]])\n","tensor([[1, 2, 3, 4, 5, 6, 0, 0],\n","        [1, 2, 3, 4, 5, 6, 7, 8]])\n","torch.Size([2, 8, 128])\n"]}],"source":["positions.masked_fill_(pos_mask, 0)\n","pos_embs = nn_pos(positions) # position embedding\n","\n","print(inputs)\n","print(positions)\n","print(pos_embs.size()) # position embedding을 수행한 결과"]},{"cell_type":"code","execution_count":47,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663511321056,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"XXYjD4uUAD9S","outputId":"ef6cf27e-a107-43f4-9761-44a33d826405"},"outputs":[{"data":{"text/plain":["tensor([[[ 8.4147e-01,  5.4030e-01,  7.6172e-01,  ...,  1.0000e+00,\n","           1.1548e-04,  1.0000e+00],\n","         [ 9.0930e-01, -4.1615e-01,  9.8705e-01,  ...,  1.0000e+00,\n","           2.3096e-04,  1.0000e+00],\n","         [ 1.4112e-01, -9.8999e-01,  5.1731e-01,  ...,  1.0000e+00,\n","           3.4643e-04,  1.0000e+00],\n","         ...,\n","         [-2.7942e-01,  9.6017e-01, -8.8542e-01,  ...,  1.0000e+00,\n","           6.9287e-04,  1.0000e+00],\n","         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n","           0.0000e+00,  1.0000e+00],\n","         [ 0.0000e+00,  1.0000e+00,  0.0000e+00,  ...,  1.0000e+00,\n","           0.0000e+00,  1.0000e+00]],\n","\n","        [[ 8.4147e-01,  5.4030e-01,  7.6172e-01,  ...,  1.0000e+00,\n","           1.1548e-04,  1.0000e+00],\n","         [ 9.0930e-01, -4.1615e-01,  9.8705e-01,  ...,  1.0000e+00,\n","           2.3096e-04,  1.0000e+00],\n","         [ 1.4112e-01, -9.8999e-01,  5.1731e-01,  ...,  1.0000e+00,\n","           3.4643e-04,  1.0000e+00],\n","         ...,\n","         [-2.7942e-01,  9.6017e-01, -8.8542e-01,  ...,  1.0000e+00,\n","           6.9287e-04,  1.0000e+00],\n","         [ 6.5699e-01,  7.5390e-01, -2.1963e-01,  ...,  1.0000e+00,\n","           8.0835e-04,  1.0000e+00],\n","         [ 9.8936e-01, -1.4550e-01,  6.0082e-01,  ...,  1.0000e+00,\n","           9.2383e-04,  1.0000e+00]]])"]},"execution_count":47,"metadata":{},"output_type":"execute_result"}],"source":["pos_embs"]},{"cell_type":"code","execution_count":48,"metadata":{"id":"MDQJDam190pM"},"outputs":[{"data":{"text/plain":["torch.Size([2, 8, 128])"]},"execution_count":48,"metadata":{},"output_type":"execute_result"}],"source":["input_sums = input_embs + pos_embs\n","input_sums.shape # 더해주었기 때문에 차원에 변화없음"]},{"cell_type":"markdown","metadata":{"id":"KEZG5ZBIANDR"},"source":["## Scaled Dot Product Attention\n","encoder-decoder attention의 구조"]},{"cell_type":"markdown","metadata":{},"source":["input: ([2, 2, 8])"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[3220, 3648,  199, 4001, 3802, 3634,    0,    0],\n","        [ 192, 3650,   54, 3879, 3640, 3726, 3802, 3634]])"]},"execution_count":49,"metadata":{},"output_type":"execute_result"}],"source":["inputs"]},{"cell_type":"markdown","metadata":{},"source":["- Q.size(0): 2\n","- Q.size(1): 8\n","- K.size(1): 8"]},{"cell_type":"code","execution_count":51,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663511369002,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"woFU4TQW-QgM","outputId":"4be02436-e723-4b2f-cf3d-6695ac8461e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 8])\n","tensor([[False, False, False, False, False, False,  True,  True],\n","        [False, False, False, False, False, False,  True,  True],\n","        [False, False, False, False, False, False,  True,  True],\n","        [False, False, False, False, False, False,  True,  True],\n","        [False, False, False, False, False, False,  True,  True],\n","        [False, False, False, False, False, False,  True,  True],\n","        [False, False, False, False, False, False,  True,  True],\n","        [False, False, False, False, False, False,  True,  True]])\n"]}],"source":["Q = input_sums #([2, 8, 128])\n","K = input_sums\n","V = input_sums\n","attn_mask = inputs.eq(0).unsqueeze(1).expand(Q.size(0), Q.size(1), K.size(1)) #unsqueeze : 1인 차원을 생성하는 함수\n","print(attn_mask.size())\n","print(attn_mask[0]) # 첫번째 문장 [3220, 3648,  199, 4001, 3802, 3634,    0,    0]에 대한 mask결과"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"data":{"text/plain":["tensor([[False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False]])"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["attn_mask[1]"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663511518839,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"Oz_YKSaYAQ3j","outputId":"84fd2acf-2d78-4d27-d66f-ce3bf7c6730a"},"outputs":[{"data":{"text/plain":["tensor([[False, False, False, False, False, False,  True,  True],\n","        [False, False, False, False, False, False, False, False]])"]},"execution_count":59,"metadata":{},"output_type":"execute_result"}],"source":["inputs.eq(0) #shape: ([2, 8])"]},{"cell_type":"code","execution_count":61,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663511521567,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"ig4-twflAwBI","outputId":"11f8ab5d-5c7a-41d7-a3a2-d92db28704ab"},"outputs":[{"data":{"text/plain":["tensor([[[False, False, False, False, False, False,  True,  True]],\n","\n","        [[False, False, False, False, False, False, False, False]]])"]},"execution_count":61,"metadata":{},"output_type":"execute_result"}],"source":["inputs.eq(0).unsqueeze(1) # 1인 차원을 생성해 ([2, 1, 8])이 됨"]},{"cell_type":"code","execution_count":64,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663511681906,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"FtpI5L8yA2J2","outputId":"b8087bb7-f811-4d46-b99f-d97b93f2fce3"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 8])\n","tensor([[196.1419,  98.5726,  47.7537,  77.1162,  98.8755,  49.4141,  38.6236,\n","          38.6236],\n","        [ 98.5726, 203.6228,  67.5878,  72.4998,  86.4031,  40.6627,  69.5832,\n","          69.5832],\n","        [ 47.7537,  67.5878, 188.7086,  69.5917,  52.2406,  59.2924,  41.7138,\n","          41.7138],\n","        [ 77.1162,  72.4998,  69.5917, 189.9413,  75.4631,  94.9287,  34.8130,\n","          34.8130],\n","        [ 98.8755,  86.4031,  52.2406,  75.4631, 212.7753,  80.7413,  66.2556,\n","          66.2556],\n","        [ 49.4141,  40.6627,  59.2924,  94.9287,  80.7413, 202.9022,  41.8396,\n","          41.8396],\n","        [ 38.6236,  69.5832,  41.7138,  34.8130,  66.2556,  41.8396, 174.3914,\n","         174.3914],\n","        [ 38.6236,  69.5832,  41.7138,  34.8130,  66.2556,  41.8396, 174.3914,\n","         174.3914]], grad_fn=<SelectBackward>)\n"]}],"source":["scores = torch.matmul(Q, K.transpose(2, 1)) #Q(K^T)연산 수행\n","print(scores.size())\n","print(scores[0]) #첫번째 문장에 대한 단어들의 상호가중치"]},{"cell_type":"markdown","metadata":{"id":"Lkd1SrHGBJB7"},"source":["### Scale"]},{"cell_type":"code","execution_count":65,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1294,"status":"ok","timestamp":1663511686863,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"9z5VKZBBBDoz","outputId":"33c1aabc-c651-431e-dbac-71c1a7103b25"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 8])\n","tensor([[24.5177, 12.3216,  5.9692,  9.6395, 12.3594,  6.1768,  4.8279,  4.8279],\n","        [12.3216, 25.4529,  8.4485,  9.0625, 10.8004,  5.0828,  8.6979,  8.6979],\n","        [ 5.9692,  8.4485, 23.5886,  8.6990,  6.5301,  7.4116,  5.2142,  5.2142],\n","        [ 9.6395,  9.0625,  8.6990, 23.7427,  9.4329, 11.8661,  4.3516,  4.3516],\n","        [12.3594, 10.8004,  6.5301,  9.4329, 26.5969, 10.0927,  8.2820,  8.2820],\n","        [ 6.1768,  5.0828,  7.4116, 11.8661, 10.0927, 25.3628,  5.2300,  5.2300],\n","        [ 4.8279,  8.6979,  5.2142,  4.3516,  8.2820,  5.2300, 21.7989, 21.7989],\n","        [ 4.8279,  8.6979,  5.2142,  4.3516,  8.2820,  5.2300, 21.7989, 21.7989]],\n","       grad_fn=<SelectBackward>)\n"]}],"source":["d_head = 64 \n","scores = scores.mul(1/d_head**0.5)\n","print(scores.size())\n","print(scores[0])"]},{"cell_type":"markdown","metadata":{"id":"xmLXaI-uBjLb"},"source":["### mask"]},{"cell_type":"code","execution_count":66,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":484,"status":"ok","timestamp":1663511711875,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"Q_1kXf_3BMJL","outputId":"82858e1b-6599-48e2-e54c-c42cb74b497e"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 8])\n","tensor([[ 2.4518e+01,  1.2322e+01,  5.9692e+00,  9.6395e+00,  1.2359e+01,\n","          6.1768e+00, -1.0000e+09, -1.0000e+09],\n","        [ 1.2322e+01,  2.5453e+01,  8.4485e+00,  9.0625e+00,  1.0800e+01,\n","          5.0828e+00, -1.0000e+09, -1.0000e+09],\n","        [ 5.9692e+00,  8.4485e+00,  2.3589e+01,  8.6990e+00,  6.5301e+00,\n","          7.4116e+00, -1.0000e+09, -1.0000e+09],\n","        [ 9.6395e+00,  9.0625e+00,  8.6990e+00,  2.3743e+01,  9.4329e+00,\n","          1.1866e+01, -1.0000e+09, -1.0000e+09],\n","        [ 1.2359e+01,  1.0800e+01,  6.5301e+00,  9.4329e+00,  2.6597e+01,\n","          1.0093e+01, -1.0000e+09, -1.0000e+09],\n","        [ 6.1768e+00,  5.0828e+00,  7.4116e+00,  1.1866e+01,  1.0093e+01,\n","          2.5363e+01, -1.0000e+09, -1.0000e+09],\n","        [ 4.8279e+00,  8.6979e+00,  5.2142e+00,  4.3516e+00,  8.2820e+00,\n","          5.2300e+00, -1.0000e+09, -1.0000e+09],\n","        [ 4.8279e+00,  8.6979e+00,  5.2142e+00,  4.3516e+00,  8.2820e+00,\n","          5.2300e+00, -1.0000e+09, -1.0000e+09]], grad_fn=<SelectBackward>)\n"]}],"source":["scores.masked_fill_(attn_mask, -1e9) #mask에 해당하는 부분만 값 변환\n","print(scores.size())\n","print(scores[0]) #mask를 수행한 부분이 -1.0000e+09로 매우 작은 값"]},{"cell_type":"markdown","metadata":{"id":"l-NRnDM0B9Wr"},"source":["### Softmax\n","attention score를 확률값으로 변환"]},{"cell_type":"code","execution_count":67,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663511817750,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"-5Vntm7FBkop","outputId":"e00bab0c-57fa-4007-a589-892642eeba0a"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 8])\n","tensor([[9.9999e-01, 5.0497e-06, 8.7998e-09, 3.4552e-07, 5.2446e-06, 1.0830e-08,\n","         0.0000e+00, 0.0000e+00],\n","        [1.9823e-06, 1.0000e+00, 4.1218e-08, 7.6164e-08, 4.3303e-07, 1.4237e-09,\n","         0.0000e+00, 0.0000e+00],\n","        [2.2285e-08, 2.6591e-07, 1.0000e+00, 3.4160e-07, 3.9047e-08, 9.4278e-08,\n","         0.0000e+00, 0.0000e+00],\n","        [7.5004e-07, 4.2118e-07, 2.9282e-07, 9.9999e-01, 6.1001e-07, 6.9513e-06,\n","         0.0000e+00, 0.0000e+00],\n","        [6.5576e-07, 1.3793e-07, 1.9279e-09, 3.5137e-08, 1.0000e+00, 6.7967e-08,\n","         0.0000e+00, 0.0000e+00],\n","        [4.6518e-09, 1.5579e-09, 1.5991e-08, 1.3755e-06, 2.3349e-07, 1.0000e+00,\n","         0.0000e+00, 0.0000e+00],\n","        [1.1883e-02, 5.6967e-01, 1.7486e-02, 7.3801e-03, 3.7582e-01, 1.7763e-02,\n","         0.0000e+00, 0.0000e+00],\n","        [1.1883e-02, 5.6967e-01, 1.7486e-02, 7.3801e-03, 3.7582e-01, 1.7763e-02,\n","         0.0000e+00, 0.0000e+00]], grad_fn=<SelectBackward>)\n"]}],"source":["attn_prob = nn.Softmax(dim=-1)(scores)\n","print(attn_prob.size())\n","print(attn_prob[0])"]},{"cell_type":"markdown","metadata":{},"source":["### 확률값을 V와 곱해줌"]},{"cell_type":"code","execution_count":68,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663511839157,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"ECUC1TX4B-bM","outputId":"1f00a160-b866-4729-cf63-6adcb279df1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 128])\n"]}],"source":["context = torch.matmul(attn_prob, V)\n","print(context.size())"]},{"cell_type":"code","execution_count":84,"metadata":{"id":"5FFqWLu1CD26"},"outputs":[],"source":["# 위 과정을 class로 변환\n","class ScaledDotProductAttention(nn.Module):\n","    def __init__(self,d_head):\n","        super().__init__()\n","        self.scale = 1/ (d_head**0.5) #scaling\n","\n","    def forward(self,Q,K,V,attn_mask):\n","        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n","        scores.masked_fill_(attn_mask, -1e9)\n","        attn_prob = nn.Softmax(dim=-1)(scores)\n","        context = torch.matmul(attn_prob, V)\n","        return context, attn_prob"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"bMgBX1eCKHJw"},"outputs":[],"source":["# dropout도 함께 적용한 경우: config에 dropout수치에 대한 정보가 추가적으로 필요\n","'''\n","class ScaledDotProductAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.dropout = nn.Dropout(config.dropout)\n","        self.scale = 1 / (self.config.d_head ** 0.5)\n","\n","    def forward(self, Q, K, V, attn_mask):\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        scores = torch.matmul(Q, K.transpose(-1, -2))\n","        scores = scores.mul_(self.scale)\n","        scores.masked_fill_(attn_mask, -1e9)\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        attn_prob = nn.Softmax(dim=-1)(scores)\n","        attn_prob = self.dropout(attn_prob)\n","        # (bs, n_head, n_q_seq, d_v)\n","        context = torch.matmul(attn_prob, V)\n","        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n","        return context, attn_prob\n","'''"]},{"cell_type":"markdown","metadata":{"id":"clg8s36aCabL"},"source":["## Multi-Head Attention\n","head의 개수가 2개, head의 dimension이 64라고 가정"]},{"cell_type":"code","execution_count":72,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663512240790,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"NkAnXNw4CZEL","outputId":"7a46a21a-bf86-4f9b-dcaa-dc69764b42fe"},"outputs":[{"name":"stdout","output_type":"stream","text":["batch_size: 2\n","attn_mask.shape(): torch.Size([2, 8, 8])\n"]}],"source":["Q = input_sums\n","K = input_sums\n","V = input_sums\n","attn_mask = inputs.eq(0).unsqueeze(1).expand(Q.size(0), Q.size(1), K.size(1))\n","\n","batch_size = Q.size(0)\n","n_head = 2\n","\n","print(f'batch_size: {batch_size}')\n","print(f'attn_mask.shape(): {attn_mask.shape}')\n"]},{"cell_type":"code","execution_count":79,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663512179076,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"dj413DvyDJNp","outputId":"c38bcc85-64a3-4a20-eb15-1533e07089c5"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 128])\n","torch.Size([2, 8, 2, 64])\n","torch.Size([2, 2, 8, 64])\n"]}],"source":["# Q를 head 단위로 나누기\n","W_Q = nn.Linear(d_hidn, n_head * d_head)\n","W_K = nn.Linear(d_hidn, n_head * d_head)\n","W_V = nn.Linear(d_hidn, n_head * d_head)\n","\n","q_s = W_Q(Q)\n","# (bs, n_seq, n_head * d_head) #n_head: 2, d_head: 64\n","print(q_s.size())\n","\n","# (bs, n_seq, n_head, d_head)\n","q_s = q_s.view(batch_size, -1, n_head, d_head) #reshape\n","print(q_s.size())\n","\n","# (bs, n_head, n_seq, d_head)\n","q_s = q_s.transpose(1,2)\n","print(q_s.size())"]},{"cell_type":"code","execution_count":80,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1663512342319,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"BDrrtJwVDWuS","outputId":"d52c2874-810f-45e7-ccbf-9734f1ece504"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 2, 8, 64]) torch.Size([2, 2, 8, 64]) torch.Size([2, 2, 8, 64])\n"]}],"source":["# Q,K,V 다 나누기 head의 수를 2개로 가정함\n","q_s = W_Q(Q).view(batch_size, -1, n_head, d_head).transpose(1,2)\n","\n","k_s = W_K(K).view(batch_size, -1, n_head, d_head).transpose(1,2)\n","\n","v_s = W_V(V).view(batch_size, -1, n_head, d_head).transpose(1,2)\n","\n","print(q_s.size(), k_s.size(), v_s.size())"]},{"cell_type":"code","execution_count":81,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":807,"status":"ok","timestamp":1663512371805,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"AdD-VLxUD-T7","outputId":"4cf44714-d25a-4bc2-8b70-960d3a3f4075"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 8])\n","torch.Size([2, 2, 8, 8])\n"]}],"source":["# Attention Mask -> Multi Head로 변경\n","print(attn_mask.size())\n","attn_mask = attn_mask.unsqueeze(1).repeat(1, n_head, 1, 1)\n","print(attn_mask.size()) # 원래 ([2, 8, 8]) -> head추가"]},{"cell_type":"markdown","metadata":{"id":"8l15sdE6EK9d"},"source":["### Attention\n","이전에 만들어둔 ScaledDotProductAttention을 활용"]},{"cell_type":"code","execution_count":87,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1009,"status":"ok","timestamp":1663512458668,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"cBfwESzOEFwL","outputId":"ecc8eef3-d7a9-4049-c863-ee6320432c6c"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 2, 8, 64])\n","torch.Size([2, 2, 8, 8])\n"]}],"source":["scaled_dot_attn = ScaledDotProductAttention(d_head)\n","context, attn_prob = scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n","print(context.size())\n","print(attn_prob.size())"]},{"cell_type":"markdown","metadata":{"id":"4svEYvY9EqoR"},"source":["### Concat"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"data":{"text/plain":["torch.Size([2, 8, 2, 64])"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["context.transpose(1, 2).shape # 두개의 차원을 맞교환"]},{"cell_type":"markdown","metadata":{},"source":["- narrow, view, expand 등을 사용하기 위해서는 새로운 텐서로 할당하는 것이 아니라 기존의 tensor와 같은 메모리공간을 공유하여 보여주기 때문에 텐서가 contiguous해야함\n","- view에서 -1은 다른 차원들로부터 추론됨"]},{"cell_type":"code","execution_count":95,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1663512529438,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"wFaqHiRXEa1q","outputId":"edec9bcd-c739-4801-cede-01ec92eaee61"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 128])\n"]}],"source":["context = context.transpose(1, 2).contiguous().view(batch_size, -1, n_head * d_head) #모든 차원을 사용해서 사라짐\n","print(context.size())"]},{"cell_type":"markdown","metadata":{"id":"VS3iT-NqE-eP"},"source":["### Linear"]},{"cell_type":"code","execution_count":96,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663512611377,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"GSw7y6zAEsMF","outputId":"c9a0d34f-7f95-4b46-8ab0-d5c160cc77ae"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 128])\n"]}],"source":["linear = nn.Linear(n_head * d_head, d_hidn)\n","# (bs, n_seq, d_hidn)\n","output = linear(context)\n","print(output.size()) #입력 Q와 동일한 Self-Attention 값"]},{"cell_type":"markdown","metadata":{"id":"siSlL91HFBvF"},"source":["위 절차를 하나의 클래스로 구현"]},{"cell_type":"code","execution_count":97,"metadata":{"id":"h8ctruqWFAZx"},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_hidn, n_head, d_head):\n","        super().__init__()\n","        self.d_hidn = d_hidn # 128\n","        self.n_head = n_head # 2\n","        self.d_head = d_head # 64\n","\n","        self.W_Q = nn.Linear(d_hidn, n_head * d_head)\n","        self.W_K = nn.Linear(d_hidn, n_head * d_head)\n","        self.W_V = nn.Linear(d_hidn, n_head * d_head)\n","        \n","        self.scaled_dot_attn = ScaledDotProductAttention(d_head)\n","        \n","        self.linear = nn.Linear(n_head * d_head, d_hidn)\n","\n","    def forward(self, Q, K, V, attn_mask):\n","        batch_size = Q.size(0)\n","\n","        q_s = self.W_Q(Q).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)\n","\n","        k_s = self.W_K(K).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)\n","\n","        v_s = self.W_V(V).view(batch_size, -1, self.n_head, self.d_head).transpose(1,2)\n","\n","\n","        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.n_head, 1, 1)\n","\n","\n","        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n","\n","        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.n_head * self.d_head)\n","\n","        output = self.linear(context)\n","\n","        return output, attn_prob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EtvyPbukKJ4O"},"outputs":[],"source":["# dropout을 적용해준 경우\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n","        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","    def forward(self, Q, K, V, attn_mask):\n","        batch_size = Q.size(0)\n","        # (bs, n_head, n_q_seq, d_head)\n","        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","        # (bs, n_head, n_k_seq, d_head)\n","        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","        # (bs, n_head, n_v_seq, d_head)\n","        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n","\n","        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n","        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n","        # (bs, n_head, n_q_seq, h_head * d_head)\n","        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n","        # (bs, n_head, n_q_seq, e_embd)\n","        output = self.linear(context)\n","        output = self.dropout(output)\n","        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n","        return output, attn_prob"]},{"cell_type":"markdown","metadata":{"id":"MIjabZDFFIi3"},"source":["## Masked Multi-Head Attention"]},{"cell_type":"code","execution_count":98,"metadata":{"id":"3ttU44lgFOxa"},"outputs":[],"source":["def get_attn_decoder_mask(seq):\n","    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n","    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n","    return subsequent_mask"]},{"cell_type":"code","execution_count":99,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663512680938,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"JJ-E62chFE39","outputId":"fcefb0cb-9cb1-41ea-930c-1ea960d93a15"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False],\n","        [False, False, False, False, False, False, False, False]])\n","tensor([[0, 1, 1, 1, 1, 1, 1, 1],\n","        [0, 0, 1, 1, 1, 1, 1, 1],\n","        [0, 0, 0, 1, 1, 1, 1, 1],\n","        [0, 0, 0, 0, 1, 1, 1, 1],\n","        [0, 0, 0, 0, 0, 1, 1, 1],\n","        [0, 0, 0, 0, 0, 0, 1, 1],\n","        [0, 0, 0, 0, 0, 0, 0, 1],\n","        [0, 0, 0, 0, 0, 0, 0, 0]])\n","tensor([[False,  True,  True,  True,  True,  True,  True,  True],\n","        [False, False,  True,  True,  True,  True,  True,  True],\n","        [False, False, False,  True,  True,  True,  True,  True],\n","        [False, False, False, False,  True,  True,  True,  True],\n","        [False, False, False, False, False,  True,  True,  True],\n","        [False, False, False, False, False, False,  True,  True],\n","        [False, False, False, False, False, False, False,  True],\n","        [False, False, False, False, False, False, False, False]])\n"]}],"source":["Q = input_sums\n","K = input_sums\n","V = input_sums\n","\n","attn_pad_mask = inputs.eq(0).unsqueeze(1).expand(Q.size(0), Q.size(1), K.size(1))\n","print(attn_pad_mask[1]) #두번째 문장에 대한 teacher forcing수행\n","attn_dec_mask = get_attn_decoder_mask(inputs)\n","print(attn_dec_mask[1])\n","attn_mask = torch.gt((attn_pad_mask + attn_dec_mask), 0)\n","print(attn_mask[1])\n","\n","batch_size = Q.size(0)\n","n_head = 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663512827787,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"psk7FXMZFz7t","outputId":"dc206856-6ed5-4095-8275-669f607657dd"},"outputs":[{"data":{"text/plain":["tensor([[[False,  True,  True,  True,  True,  True,  True,  True],\n","         [False, False,  True,  True,  True,  True,  True,  True],\n","         [False, False, False,  True,  True,  True,  True,  True],\n","         [False, False, False, False,  True,  True,  True,  True],\n","         [False, False, False, False, False,  True,  True,  True],\n","         [False, False, False, False, False, False,  True,  True],\n","         [False, False, False, False, False, False,  True,  True],\n","         [False, False, False, False, False, False,  True,  True]],\n","\n","        [[False,  True,  True,  True,  True,  True,  True,  True],\n","         [False, False,  True,  True,  True,  True,  True,  True],\n","         [False, False, False,  True,  True,  True,  True,  True],\n","         [False, False, False, False,  True,  True,  True,  True],\n","         [False, False, False, False, False,  True,  True,  True],\n","         [False, False, False, False, False, False,  True,  True],\n","         [False, False, False, False, False, False, False,  True],\n","         [False, False, False, False, False, False, False, False]]])"]},"execution_count":67,"metadata":{},"output_type":"execute_result"}],"source":["attn_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663512710638,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"aT8Bgcc5FRP3","outputId":"359cb3e9-874a-4120-ee3e-82e121bbd392"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 128]) torch.Size([2, 2, 8, 8])\n"]}],"source":["attention = MultiHeadAttention(d_hidn, n_head, d_head)\n","output, attn_prob = attention(Q, K, V, attn_mask)\n","print(output.size(), attn_prob.size())"]},{"cell_type":"markdown","metadata":{"id":"rRRRPqlIGHI3"},"source":["## FeedForward"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663512917666,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"DThqqsoBFYgb","outputId":"acc64e67-6158-458d-e2c6-4e3a53a976e5"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 512, 8])\n"]}],"source":["conv1 = nn.Conv1d(in_channels=d_hidn, out_channels=d_hidn * 4, kernel_size=1)\n","\n","ff_1 = conv1(output.transpose(1, 2))\n","print(ff_1.size())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZogFYoJIGO3L"},"outputs":[],"source":["import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PoxsBjI8GLAu"},"outputs":[],"source":["active = F.gelu\n","ff_2 = active(ff_1)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663512995439,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"D5-nJ3P0GdR9","outputId":"417421e6-7052-48d1-9c7e-6c6fb7eb3eb8"},"outputs":[{"data":{"text/plain":["torch.Size([2, 512, 8])"]},"execution_count":74,"metadata":{},"output_type":"execute_result"}],"source":["ff_2.shape"]},{"cell_type":"markdown","metadata":{"id":"QvmJ-zi9GXyG"},"source":["최근 논문에서 gelu를 쓰는 것이 더 효과적이라고 언급"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1663512987479,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"xBl6R4aFGOJX","outputId":"6764210f-f38d-4cac-c531-9c0f72044643"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2, 8, 128])\n"]}],"source":["conv2 = nn.Conv1d(in_channels=d_hidn * 4, out_channels=d_hidn, kernel_size=1)\n","ff_3 = conv2(ff_2).transpose(1, 2)\n","print(ff_3.size())"]},{"cell_type":"markdown","metadata":{"id":"sN9YtOiDGgE0"},"source":["입력과 동일한 shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Da2bwm3WGcFa"},"outputs":[],"source":["class PoswiseFeedForwardNet(nn.Module):\n","    def __init__(self, d_hidn):\n","        super().__init__()\n","\n","        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_hidn * 4, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=self.config.d_hidn * 4, out_channels=self.config.d_hidn, kernel_size=1)\n","        self.active = F.gelu\n","\n","    def forward(self, inputs):\n","        # (bs, d_ff, n_seq)\n","        output = self.active(self.conv1(inputs.transpose(1, 2)))\n","        # (bs, n_seq, d_hidn)\n","        output = self.conv2(output).transpose(1, 2)\n","        # (bs, n_seq, d_hidn)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rjWoSQ3DKM0_"},"outputs":[],"source":["class PoswiseFeedForwardNet(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n","        self.active = F.gelu\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","    def forward(self, inputs):\n","        # (bs, d_ff, n_seq)\n","        output = self.conv1(inputs.transpose(1, 2))\n","        output = self.active(output)\n","        # (bs, n_seq, d_hidn)\n","        output = self.conv2(output).transpose(1, 2)\n","        output = self.dropout(output)\n","        # (bs, n_seq, d_hidn)\n","        return output"]},{"cell_type":"markdown","metadata":{"id":"CL7ypuMtGsaN"},"source":["# 실습"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tW9vVIxGGkHv"},"outputs":[],"source":["class Config(dict):\n","    __getattr__ = dict.__getitem__\n","    __setattr__ = dict.__setitem__\n","\n","    @classmethod\n","    def load(cls, file):\n","        with open(file, 'r') as f:\n","            config = json.loads(f.read())\n","            return Config(config)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":626,"status":"ok","timestamp":1663513877534,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"lcCdwrHEGtT4","outputId":"25562104-1570-41fc-c426-35632a5a64b9"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_enc_vocab': 8007, 'n_dec_vocab': 8007, 'n_enc_seq': 256, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12}\n"]}],"source":["config = Config({\n","    \"n_enc_vocab\": len(vocab),\n","    \"n_dec_vocab\": len(vocab),\n","    \"n_enc_seq\": 256,\n","    \"n_dec_seq\": 256,\n","    \"n_layer\": 6,\n","    \"d_hidn\": 256,\n","    \"i_pad\": 0,\n","    \"d_ff\": 1024,\n","    \"n_head\": 4,\n","    \"d_head\": 64,\n","    \"dropout\": 0.1,\n","    \"layer_norm_epsilon\": 1e-12\n","})\n","print(config)"]},{"cell_type":"markdown","metadata":{"id":"OovfizakG5mP"},"source":["### Encoder layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AO1LuHbaGvgD"},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.self_attn = MultiHeadAttention(self.config)\n","        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n","        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","\n","    def forward(self, inputs, attn_mask):\n","        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n","        att_outputs = self.layer_norm1(inputs + att_outputs)\n","        # (bs, n_enc_seq, d_hidn)\n","        ffn_outputs = self.pos_ffn(att_outputs)\n","        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n","        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","        return ffn_outputs, attn_prob"]},{"cell_type":"markdown","metadata":{"id":"6AFBY8ymHBfn"},"source":["### Encoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hbCHerglHXCr"},"outputs":[],"source":["def get_attn_pad_mask(seq_q, seq_k, i_pad):\n","    batch_size, len_q = seq_q.size()\n","    batch_size, len_k = seq_k.size()\n","    pad_attn_mask = seq_k.data.eq(i_pad)\n","    pad_attn_mask= pad_attn_mask.unsqueeze(1).expand(batch_size, len_q, len_k)\n","    return pad_attn_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sukbv2kiG4Uc"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n","        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_enc_seq + 1, self.config.d_hidn))\n","        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n","\n","        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n","\n","    def forward(self, inputs):\n","        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n","        pos_mask = inputs.eq(self.config.i_pad)\n","        positions.masked_fill_(pos_mask, 0)\n","\n","\n","        outputs = self.enc_emb(inputs) + self.pos_emb(positions)\n","\n","\n","        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n","\n","        attn_probs = []\n","        for layer in self.layers:\n","\n","            outputs, attn_prob = layer(outputs, attn_mask)\n","            attn_probs.append(attn_prob)\n","\n","        return outputs, attn_probs"]},{"cell_type":"markdown","metadata":{"id":"qLL9XbRPH53D"},"source":["## Decoder layer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7Ll0eH12HCJO"},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.self_attn = MultiHeadAttention(self.config)\n","        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.dec_enc_attn = MultiHeadAttention(self.config)\n","        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n","        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","\n","    def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n","\n","        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n","        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n","\n","        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n","        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n","\n","        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n","        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n","\n","        return ffn_outputs, self_attn_prob, dec_enc_attn_prob"]},{"cell_type":"markdown","metadata":{"id":"My5qctdOIDfI"},"source":["## Decoder"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GKaa54nxH8G5"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n","        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n","        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n","\n","        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n","\n","    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n","        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n","        pos_mask = dec_inputs.eq(self.config.i_pad)\n","        positions.masked_fill_(pos_mask, 0)\n","\n","\n","        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n","\n","\n","        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n","\n","        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n","\n","        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n","\n","        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n","\n","        self_attn_probs, dec_enc_attn_probs = [], []\n","        for layer in self.layers:\n","\n","            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n","            self_attn_probs.append(self_attn_prob)\n","            dec_enc_attn_probs.append(dec_enc_attn_prob)\n","\n","        return dec_outputs, self_attn_probs, dec_enc_attn_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"epq5OnzJINym"},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.encoder = Encoder(self.config)\n","        self.decoder = Decoder(self.config)\n","\n","    def forward(self, enc_inputs, dec_inputs):\n","\n","        enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)\n","\n","        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n","\n","        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"]},{"cell_type":"markdown","metadata":{"id":"DG7zvdtQIUjO"},"source":["## Data 만들기"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"coN7Kd-VIRkg"},"outputs":[],"source":["class MovieClassification(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.transformer = Transformer(self.config)\n","        self.projection = nn.Linear(self.config.d_hidn, self.config.n_output, bias=False)\n","\n","    def forward(self, enc_inputs, dec_inputs):\n","\n","        dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs = self.transformer(enc_inputs, dec_inputs)\n","\n","        dec_outputs, _ = torch.max(dec_outputs, dim=1)\n","\n","        logits = self.projection(dec_outputs)\n","\n","        return logits, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"]},{"cell_type":"markdown","metadata":{"id":"sVmM4t6QIfnB"},"source":["## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6ihhgoHVIhmR"},"outputs":[],"source":["from tqdm import tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D2ggcUcLIXmO"},"outputs":[],"source":["class MovieDataSet(torch.utils.data.Dataset):\n","    def __init__(self, vocab, infile):\n","        self.vocab = vocab\n","        self.labels = []\n","        self.sentences = []\n","\n","        line_cnt = 0\n","        with open(infile, \"r\") as f:\n","            for line in f:\n","                line_cnt += 1\n","\n","        with open(infile, \"r\") as f:\n","            for i, line in enumerate(tqdm(f, total=line_cnt, desc=f\"Loading {infile}\", unit=\" lines\")):\n","                data = json.loads(line)\n","                self.labels.append(data[\"label\"])\n","                self.sentences.append([vocab.piece_to_id(p) for p in data[\"doc\"]])\n","\n","    def __len__(self):\n","        assert len(self.labels) == len(self.sentences)\n","        return len(self.labels)\n","\n","    def __getitem__(self, item):\n","        return (torch.tensor(self.labels[item]),\n","                torch.tensor(self.sentences[item]),\n","                torch.tensor([self.vocab.piece_to_id(\"[BOS]\")]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VJiAz8pTIgiO"},"outputs":[],"source":["# Batch 만들기\n","def movie_collate_fn(inputs):\n","    labels, enc_inputs, dec_inputs = list(zip(*inputs))\n","\n","    enc_inputs = torch.nn.utils.rnn.pad_sequence(enc_inputs, batch_first=True, padding_value=0)\n","    dec_inputs = torch.nn.utils.rnn.pad_sequence(dec_inputs, batch_first=True, padding_value=0)\n","\n","    batch = [\n","        torch.stack(labels, dim=0),\n","        enc_inputs,\n","        dec_inputs,\n","    ]\n","    return batch"]},{"cell_type":"markdown","metadata":{"id":"Bph_yo_TIpmg"},"source":["### Dataloader"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6784,"status":"ok","timestamp":1663513900472,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"gyPkROh-Ingo","outputId":"3290f22e-9bb6-4c13-a9bd-37416f98edb0"},"outputs":[{"name":"stderr","output_type":"stream","text":["Loading /content/ratings_train.json: 100%|██████████| 149995/149995 [00:04<00:00, 31449.74 lines/s]\n","Loading /content/ratings_test.json: 100%|██████████| 49997/49997 [00:01<00:00, 28793.82 lines/s]\n"]}],"source":["batch_size = 128\n","train_dataset = MovieDataSet(vocab, \"./ratings_train.json\")\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=movie_collate_fn)\n","test_dataset = MovieDataSet(vocab, \"./ratings_test.json\")\n","test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=movie_collate_fn)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8CKtSkuJXDV"},"outputs":[],"source":["def eval_epoch(config, model, data_loader):\n","    matchs = []\n","    model.eval()\n","\n","    n_word_total = 0\n","    n_correct_total = 0\n","    with tqdm(total=len(data_loader), desc=f\"Valid\") as pbar:\n","        for i, value in enumerate(data_loader):\n","            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n","\n","            outputs = model(enc_inputs, dec_inputs)\n","            logits = outputs[0]\n","            _, indices = logits.max(1)\n","\n","            match = torch.eq(indices, labels).detach()\n","            matchs.extend(match.cpu())\n","            accuracy = np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0\n","\n","            pbar.update(1)\n","            pbar.set_postfix_str(f\"Acc: {accuracy:.3f}\")\n","    return np.sum(matchs) / len(matchs) if 0 < len(matchs) else 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_-rop78rJYuw"},"outputs":[],"source":["def train_epoch(config, epoch, model, criterion, optimizer, train_loader):\n","    losses = []\n","    model.train()\n","\n","    with tqdm(total=len(train_loader), desc=f\"Train {epoch}\") as pbar:\n","        for i, value in enumerate(train_loader):\n","            labels, enc_inputs, dec_inputs = map(lambda v: v.to(config.device), value)\n","\n","            optimizer.zero_grad()\n","            outputs = model(enc_inputs, dec_inputs)\n","            logits = outputs[0]\n","\n","            loss = criterion(logits, labels)\n","            loss_val = loss.item()\n","            losses.append(loss_val)\n","\n","            loss.backward()\n","            optimizer.step()\n","\n","            pbar.update(1)\n","            pbar.set_postfix_str(f\"Loss: {loss_val:.3f} ({np.mean(losses):.3f})\")\n","    return np.mean(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1663513905816,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"UVCknddzJbqx","outputId":"96acd8ae-834e-4cc5-cd1e-409bbc3c6a41"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'n_enc_vocab': 8007, 'n_dec_vocab': 8007, 'n_enc_seq': 256, 'n_dec_seq': 256, 'n_layer': 6, 'd_hidn': 256, 'i_pad': 0, 'd_ff': 1024, 'n_head': 4, 'd_head': 64, 'dropout': 0.1, 'layer_norm_epsilon': 1e-12, 'device': device(type='cuda'), 'n_output': 2}\n"]}],"source":["config.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","config.n_output = 2\n","print(config)\n","\n","learning_rate = 5e-5\n","n_epoch = 10"]},{"cell_type":"markdown","metadata":{"id":"x6IuBQ5eKWVW"},"source":["# 최종"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XcehzMSKKXWR"},"outputs":[],"source":["import os\n","import numpy as np\n","import math\n","import matplotlib.pyplot as plt\n","import json\n","import pandas as pd\n","from IPython.display import display\n","from tqdm import tqdm, tqdm_notebook, trange\n","import sentencepiece as spm\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oAI9VL7HKbOA"},"outputs":[],"source":["def get_sinusoid_encoding_table(n_seq, d_hidn):\n","    def cal_angle(position, i_hidn):\n","        return position / np.power(10000, 2 * (i_hidn // 2) / d_hidn)\n","    def get_posi_angle_vec(position):\n","        return [cal_angle(position, i_hidn) for i_hidn in range(d_hidn)]\n","\n","    sinusoid_table = np.array([get_posi_angle_vec(i_seq) for i_seq in range(n_seq)])\n","    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])  # even index sin\n","    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])  # odd index cos\n","\n","    return sinusoid_table"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"802pDEd0KcvH"},"outputs":[],"source":["def get_attn_pad_mask(seq_q, seq_k, i_pad):\n","    batch_size, len_q = seq_q.size()\n","    batch_size, len_k = seq_k.size()\n","    pad_attn_mask = seq_k.data.eq(i_pad).unsqueeze(1).expand(batch_size, len_q, len_k)  # <pad>\n","    return pad_attn_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z0O4fxxMKd6W"},"outputs":[],"source":["def get_attn_decoder_mask(seq):\n","    subsequent_mask = torch.ones_like(seq).unsqueeze(-1).expand(seq.size(0), seq.size(1), seq.size(1))\n","    subsequent_mask = subsequent_mask.triu(diagonal=1) # upper triangular part of a matrix(2-D)\n","    return subsequent_mask"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"djABQhoQKfFt"},"outputs":[],"source":["class ScaledDotProductAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","        self.dropout = nn.Dropout(config.dropout)\n","        self.scale = 1 / (self.config.d_head ** 0.5)\n","\n","    def forward(self, Q, K, V, attn_mask):\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        scores = torch.matmul(Q, K.transpose(-1, -2)).mul_(self.scale)\n","        scores.masked_fill_(attn_mask, -1e9)\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        attn_prob = nn.Softmax(dim=-1)(scores)\n","        attn_prob = self.dropout(attn_prob)\n","        # (bs, n_head, n_q_seq, d_v)\n","        context = torch.matmul(attn_prob, V)\n","        # (bs, n_head, n_q_seq, d_v), (bs, n_head, n_q_seq, n_v_seq)\n","        return context, attn_prob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N6OpKmxvKgX5"},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.W_Q = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.W_K = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.W_V = nn.Linear(self.config.d_hidn, self.config.n_head * self.config.d_head)\n","        self.scaled_dot_attn = ScaledDotProductAttention(self.config)\n","        self.linear = nn.Linear(self.config.n_head * self.config.d_head, self.config.d_hidn)\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","    def forward(self, Q, K, V, attn_mask):\n","        batch_size = Q.size(0)\n","        # (bs, n_head, n_q_seq, d_head)\n","        q_s = self.W_Q(Q).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","        # (bs, n_head, n_k_seq, d_head)\n","        k_s = self.W_K(K).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","        # (bs, n_head, n_v_seq, d_head)\n","        v_s = self.W_V(V).view(batch_size, -1, self.config.n_head, self.config.d_head).transpose(1,2)\n","\n","        # (bs, n_head, n_q_seq, n_k_seq)\n","        attn_mask = attn_mask.unsqueeze(1).repeat(1, self.config.n_head, 1, 1)\n","\n","        # (bs, n_head, n_q_seq, d_head), (bs, n_head, n_q_seq, n_k_seq)\n","        context, attn_prob = self.scaled_dot_attn(q_s, k_s, v_s, attn_mask)\n","        # (bs, n_head, n_q_seq, h_head * d_head)\n","        context = context.transpose(1, 2).contiguous().view(batch_size, -1, self.config.n_head * self.config.d_head)\n","        # (bs, n_head, n_q_seq, e_embd)\n","        output = self.linear(context)\n","        output = self.dropout(output)\n","        # (bs, n_q_seq, d_hidn), (bs, n_head, n_q_seq, n_k_seq)\n","        return output, attn_prob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZdWRwLx8Khlj"},"outputs":[],"source":["class PoswiseFeedForwardNet(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.conv1 = nn.Conv1d(in_channels=self.config.d_hidn, out_channels=self.config.d_ff, kernel_size=1)\n","        self.conv2 = nn.Conv1d(in_channels=self.config.d_ff, out_channels=self.config.d_hidn, kernel_size=1)\n","        self.active = F.gelu\n","        self.dropout = nn.Dropout(config.dropout)\n","\n","    def forward(self, inputs):\n","        # (bs, d_ff, n_seq)\n","        output = self.active(self.conv1(inputs.transpose(1, 2)))\n","        # (bs, n_seq, d_hidn)\n","        output = self.conv2(output).transpose(1, 2)\n","        output = self.dropout(output)\n","        # (bs, n_seq, d_hidn)\n","        return output"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iHcN-GqQKi2a"},"outputs":[],"source":["class EncoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.self_attn = MultiHeadAttention(self.config)\n","        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n","        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","\n","    def forward(self, inputs, attn_mask):\n","        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","        att_outputs, attn_prob = self.self_attn(inputs, inputs, inputs, attn_mask)\n","        att_outputs = self.layer_norm1(inputs + att_outputs)\n","        # (bs, n_enc_seq, d_hidn)\n","        ffn_outputs = self.pos_ffn(att_outputs)\n","        ffn_outputs = self.layer_norm2(ffn_outputs + att_outputs)\n","        # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","        return ffn_outputs, attn_prob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ICcsLWwzKkRb"},"outputs":[],"source":["class Encoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.enc_emb = nn.Embedding(self.config.n_enc_vocab, self.config.d_hidn)\n","        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_enc_seq + 1, self.config.d_hidn))\n","        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n","\n","        self.layers = nn.ModuleList([EncoderLayer(self.config) for _ in range(self.config.n_layer)])\n","\n","    def forward(self, inputs):\n","        positions = torch.arange(inputs.size(1), device=inputs.device, dtype=inputs.dtype).expand(inputs.size(0), inputs.size(1)).contiguous() + 1\n","        pos_mask = inputs.eq(self.config.i_pad)\n","        positions.masked_fill_(pos_mask, 0)\n","\n","        # (bs, n_enc_seq, d_hidn)\n","        outputs = self.enc_emb(inputs) + self.pos_emb(positions)\n","\n","        # (bs, n_enc_seq, n_enc_seq)\n","        attn_mask = get_attn_pad_mask(inputs, inputs, self.config.i_pad)\n","\n","        attn_probs = []\n","        for layer in self.layers:\n","            # (bs, n_enc_seq, d_hidn), (bs, n_head, n_enc_seq, n_enc_seq)\n","            outputs, attn_prob = layer(outputs, attn_mask)\n","            attn_probs.append(attn_prob)\n","        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n","        return outputs, attn_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B_7q2dbCKmXN"},"outputs":[],"source":["class DecoderLayer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.self_attn = MultiHeadAttention(self.config)\n","        self.layer_norm1 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.dec_enc_attn = MultiHeadAttention(self.config)\n","        self.layer_norm2 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","        self.pos_ffn = PoswiseFeedForwardNet(self.config)\n","        self.layer_norm3 = nn.LayerNorm(self.config.d_hidn, eps=self.config.layer_norm_epsilon)\n","\n","    def forward(self, dec_inputs, enc_outputs, self_attn_mask, dec_enc_attn_mask):\n","        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq)\n","        self_att_outputs, self_attn_prob = self.self_attn(dec_inputs, dec_inputs, dec_inputs, self_attn_mask)\n","        self_att_outputs = self.layer_norm1(dec_inputs + self_att_outputs)\n","        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_enc_seq)\n","        dec_enc_att_outputs, dec_enc_attn_prob = self.dec_enc_attn(self_att_outputs, enc_outputs, enc_outputs, dec_enc_attn_mask)\n","        dec_enc_att_outputs = self.layer_norm2(self_att_outputs + dec_enc_att_outputs)\n","        # (bs, n_dec_seq, d_hidn)\n","        ffn_outputs = self.pos_ffn(dec_enc_att_outputs)\n","        ffn_outputs = self.layer_norm3(dec_enc_att_outputs + ffn_outputs)\n","        # (bs, n_dec_seq, d_hidn), (bs, n_head, n_dec_seq, n_dec_seq), (bs, n_head, n_dec_seq, n_enc_seq)\n","        return ffn_outputs, self_attn_prob, dec_enc_attn_prob"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ngbc8Ns1Km9q"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.dec_emb = nn.Embedding(self.config.n_dec_vocab, self.config.d_hidn)\n","        sinusoid_table = torch.FloatTensor(get_sinusoid_encoding_table(self.config.n_dec_seq + 1, self.config.d_hidn))\n","        self.pos_emb = nn.Embedding.from_pretrained(sinusoid_table, freeze=True)\n","\n","        self.layers = nn.ModuleList([DecoderLayer(self.config) for _ in range(self.config.n_layer)])\n","\n","    def forward(self, dec_inputs, enc_inputs, enc_outputs):\n","        positions = torch.arange(dec_inputs.size(1), device=dec_inputs.device, dtype=dec_inputs.dtype).expand(dec_inputs.size(0), dec_inputs.size(1)).contiguous() + 1\n","        pos_mask = dec_inputs.eq(self.config.i_pad)\n","        positions.masked_fill_(pos_mask, 0)\n","\n","        # (bs, n_dec_seq, d_hidn)\n","        dec_outputs = self.dec_emb(dec_inputs) + self.pos_emb(positions)\n","\n","        # (bs, n_dec_seq, n_dec_seq)\n","        dec_attn_pad_mask = get_attn_pad_mask(dec_inputs, dec_inputs, self.config.i_pad)\n","        # (bs, n_dec_seq, n_dec_seq)\n","        dec_attn_decoder_mask = get_attn_decoder_mask(dec_inputs)\n","        # (bs, n_dec_seq, n_dec_seq)\n","        dec_self_attn_mask = torch.gt((dec_attn_pad_mask + dec_attn_decoder_mask), 0)\n","        # (bs, n_dec_seq, n_enc_seq)\n","        dec_enc_attn_mask = get_attn_pad_mask(dec_inputs, enc_inputs, self.config.i_pad)\n","\n","        self_attn_probs, dec_enc_attn_probs = [], []\n","        for layer in self.layers:\n","            # (bs, n_dec_seq, d_hidn), (bs, n_dec_seq, n_dec_seq), (bs, n_dec_seq, n_enc_seq)\n","            dec_outputs, self_attn_prob, dec_enc_attn_prob = layer(dec_outputs, enc_outputs, dec_self_attn_mask, dec_enc_attn_mask)\n","            self_attn_probs.append(self_attn_prob)\n","            dec_enc_attn_probs.append(dec_enc_attn_prob)\n","        # (bs, n_dec_seq, d_hidn), [(bs, n_dec_seq, n_dec_seq)], [(bs, n_dec_seq, n_enc_seq)]S\n","        return dec_outputs, self_attn_probs, dec_enc_attn_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lyGhhUt2Kpcf"},"outputs":[],"source":["class Transformer(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","        self.config = config\n","\n","        self.encoder = Encoder(self.config)\n","        self.decoder = Decoder(self.config)\n","\n","    def forward(self, enc_inputs, dec_inputs):\n","        # (bs, n_enc_seq, d_hidn), [(bs, n_head, n_enc_seq, n_enc_seq)]\n","        enc_outputs, enc_self_attn_probs = self.encoder(enc_inputs)\n","        # (bs, n_seq, d_hidn), [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n","        dec_outputs, dec_self_attn_probs, dec_enc_attn_probs = self.decoder(dec_inputs, enc_inputs, enc_outputs)\n","        # (bs, n_dec_seq, n_dec_vocab), [(bs, n_head, n_enc_seq, n_enc_seq)], [(bs, n_head, n_dec_seq, n_dec_seq)], [(bs, n_head, n_dec_seq, n_enc_seq)]\n","        return dec_outputs, enc_self_attn_probs, dec_self_attn_probs, dec_enc_attn_probs"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":437},"executionInfo":{"elapsed":181889,"status":"error","timestamp":1663514286114,"user":{"displayName":"이동호(일반대학원 디지털애널리틱스 융합협동과정)","userId":"18126130520433069965"},"user_tz":-540},"id":"fmD6BKZIJNyl","outputId":"a0a27c40-9a43-4916-829b-ca306322ae11"},"outputs":[],"source":["model = MovieClassification(config)\n","model.to(config.device)\n","\n","criterion = torch.nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n","\n","losses, scores = [], []\n","for epoch in range(n_epoch):\n","    loss = train_epoch(config, epoch, model, criterion, optimizer, train_loader)\n","    score = eval_epoch(config, model, test_loader)\n","\n","    losses.append(loss)\n","    scores.append(score)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VpPJFqa_JRpA"},"outputs":[],"source":["data = {\n","    \"loss\": losses,\n","    \"score\": scores\n","}\n","df = pd.DataFrame(data)\n","display(df)\n","\n","# graph\n","plt.figure(figsize=[12, 4])\n","plt.plot(losses, label=\"loss\")\n","plt.plot(scores, label=\"score\")\n","plt.legend()\n","plt.xlabel('Epoch')\n","plt.ylabel('Value')\n","plt.show()"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1YEiohDWiOCpltazUmI6WqK33j0vWdTh4","timestamp":1691676974748}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"}},"nbformat":4,"nbformat_minor":0}
